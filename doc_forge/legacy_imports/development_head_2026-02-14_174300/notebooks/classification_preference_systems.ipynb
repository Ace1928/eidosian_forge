{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; line-height: 1.6; color: #f0f0f0; margin-bottom: 20px; background-color: #2c3e50; border-radius: 12px; padding: 15px; box-shadow: 0 8px 16px rgba(0,0,0,0.4);\">\n",
    "    <h2 style=\"color: #ecf0f1; border-bottom: 2px solid #34495e; padding-bottom: 8px; margin-bottom: 15px; display: flex; align-items: center;\">\n",
    "        <span style=\"color: #3498db; font-size: 1.2em; margin-right: 8px;\">&#x1F4E6;</span>\n",
    "        <span style=\"font-weight: bold; font-size: 1.1em;\">Eidosian Classification & Preference Systems</span>\n",
    "    </h2>\n",
    "    <p style=\"font-size: 0.85em; color: #bdc3c7; margin-bottom: 15px;\">\n",
    "        <span style=\"font-weight: bold; color:#ecf0f1;\">Eidosian Classification & Preference Systems</span> is a comprehensive exploration of various machine learning algorithms and techniques for classification, policy optimization, preference modeling, and homeostatic control. This notebook provides a detailed walkthrough of each method, complete with code examples, explanations, and visualizations.\n",
    "    </p>\n",
    "    <p style=\"font-size: 0.85em; color: #bdc3c7; margin-bottom: 15px;\">\n",
    "        We delve into the core concepts of each algorithm, providing both theoretical background and practical implementation details. This includes Decision Trees, Support Vector Machines, Neural Networks, Policy Gradient Methods, Q-Learning, Actor-Critic Methods, Multi-Criteria Decision Analysis, Preference Learning, Fuzzy Logic Systems, and PID Controllers.\n",
    "    </p>\n",
    "    <p style=\"font-size: 0.85em; color: #bdc3c7; margin-bottom: 15px;\">\n",
    "        This notebook is designed to be a living document, continually updated with the latest advancements in machine learning and control systems. It serves as a valuable resource for both beginners and experts looking to deepen their understanding and practical skills in these areas.\n",
    "    </p>\n",
    "    <div style=\"margin-bottom: 15px;\">\n",
    "        <h3 style=\"color: #3498db; font-size: 1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "        <span style=\"margin-right: 5px; font-size: 1em;\">&#x2699;</span>\n",
    "        <span style=\"font-weight: bold;\">Table of Contents</span>\n",
    "        </h3>\n",
    "        <ul style=\"list-style-type: none; padding-left: 10px; font-size: 0.85em;\">\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#classification\" style=\"color: #2ecc71; text-decoration: none; font-weight: bold;\">1. Classification Algorithms</a></li>\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#policy_optimization\" style=\"color: #e74c3c; text-decoration: none; font-weight: bold;\">2. Policy Optimization Techniques</a></li>\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#preferential_systems\" style=\"color: #9b59b6; text-decoration: none; font-weight: bold;\">3. Preferential Systems</a></li>\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#homeostatic_algorithms\" style=\"color: #3498db; text-decoration: none; font-weight: bold;\">4. Homeostatic Digital Algorithms</a></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <p style=\"font-size: 0.75em; color: #95a5a6; margin-top: 15px; font-style: italic;\">\n",
    "        <span style=\"font-weight: bold; color:#ecf0f1;\">Note:</span> This notebook provides a comprehensive overview of various machine learning and control techniques. Each section includes detailed explanations, code examples, and visualizations to enhance understanding.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Roboto', sans-serif; line-height: 1.6; color: #f0f0f0; margin-bottom: 20px; background-color: #2c3e50; border-radius: 12px; padding: 15px; box-shadow: 0 8px 16px rgba(0,0,0,0.4);\">\n",
    "    <h2 id=\"classification\" style=\"color: #ecf0f1; border-bottom: 2px solid #34495e; padding-bottom: 8px; margin-bottom: 15px; display: flex; align-items: center;\">\n",
    "        <span style=\"color: #3498db; font-size: 1.4em; margin-right: 8px;\">&#x1F4BB;</span>\n",
    "        <span style=\"font-weight: bold; font-size: 1.3em;\">1. Classification Algorithms</span>\n",
    "    </h2>\n",
    "    <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 15px;\">\n",
    "        Explore various classification algorithms, each with its unique approach to categorizing data.\n",
    "    </p>\n",
    "    <div style=\"margin-bottom: 15px;\">\n",
    "        <h3 style=\"color: #3498db; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px;\">Table of Contents</h3>\n",
    "        <ul style=\"list-style-type: none; padding-left: 10px; font-size: 0.95em;\">\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#decision_trees\" style=\"color: #2ecc71; text-decoration: none; font-weight: bold;\">a. Decision Trees</a></li>\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#svm\" style=\"color: #e74c3c; text-decoration: none; font-weight: bold;\">b. Support Vector Machines (SVMs)</a></li>\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#neural_networks\" style=\"color: #9b59b6; text-decoration: none; font-weight: bold;\">c. Neural Networks (Deep Learning)</a></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"decision_trees\" style=\"color: #2ecc71; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x1F333;</span>\n",
    "            <span style=\"font-weight: bold;\">a. Decision Trees</span>\n",
    "        </h3>\n",
    "        <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> Decision Trees are a non-parametric supervised learning method used for classification and regression. They work by splitting the dataset into subsets based on feature values. Each internal node represents a test on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label (for classification) or continuous value (for regression). They are intuitive and mimic human decision-making, but can overfit if not properly pruned.\n",
    "        </p>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"svm\" style=\"color: #e74c3c; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x269B;</span>\n",
    "            <span style=\"font-weight: bold;\">b. Support Vector Machines (SVMs)</span>\n",
    "        </h3>\n",
    "         <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> Support Vector Machines aim to find the best hyperplane that separates data points of different classes with the maximum margin. For non-linearly separable data, kernel functions (like radial basis functions) map input data into higher dimensions where they can be separated linearly. SVMs are powerful classifiers especially in high-dimensional spaces.\n",
    "        </p>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"neural_networks\" style=\"color: #9b59b6; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x1F4A1;</span>\n",
    "            <span style=\"font-weight: bold;\">c. Neural Networks (Deep Learning)</span>\n",
    "        </h3>\n",
    "         <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> Neural networks are composed of layers of neurons. Each neuron applies a weighted sum followed by a non-linear activation function, enabling the network to model complex non-linear relationships. Training involves adjusting weights based on the error between predicted and actual outputs using backpropagation.\n",
    "        </p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Roboto', sans-serif; line-height: 1.6; color: #f0f0f0; margin-bottom: 20px; background-color: #2c3e50; border-radius: 12px; padding: 15px; box-shadow: 0 8px 16px rgba(0,0,0,0.4);\">\n",
    "    <h2 id=\"policy_optimization\" style=\"color: #ecf0f1; border-bottom: 2px solid #34495e; padding-bottom: 8px; margin-bottom: 15px; display: flex; align-items: center;\">\n",
    "        <span style=\"color: #3498db; font-size: 1.4em; margin-right: 8px;\">&#x1F3AF;</span>\n",
    "        <span style=\"font-weight: bold; font-size: 1.3em;\">2. Policy Optimization Techniques</span>\n",
    "    </h2>\n",
    "    <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 15px;\">\n",
    "        Explore various policy optimization techniques used in reinforcement learning.\n",
    "    </p>\n",
    "    <div style=\"margin-bottom: 15px;\">\n",
    "        <h3 style=\"color: #3498db; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px;\">Table of Contents</h3>\n",
    "        <ul style=\"list-style-type: none; padding-left: 10px; font-size: 0.95em;\">\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#policy_gradient\" style=\"color: #2ecc71; text-decoration: none; font-weight: bold;\">a. Policy Gradient Methods (REINFORCE)</a></li>\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#q_learning\" style=\"color: #e74c3c; text-decoration: none; font-weight: bold;\">b. Q-Learning and Deep Q-Networks (DQN)</a></li>\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#actor_critic\" style=\"color: #9b59b6; text-decoration: none; font-weight: bold;\">c. Actor-Critic Methods</a></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"policy_gradient\" style=\"color: #2ecc71; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x1F3C6;</span>\n",
    "            <span style=\"font-weight: bold;\">a. Policy Gradient Methods (REINFORCE)</span>\n",
    "        </h3>\n",
    "        <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> Policy gradient methods optimize the policy directly by computing gradients of expected rewards with respect to policy parameters. The REINFORCE algorithm is a Monte Carlo method that updates the policy by sampling trajectories and adjusting parameters to maximize returns.\n",
    "        </p>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"q_learning\" style=\"color: #e74c3c; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x1F4A1;</span>\n",
    "            <span style=\"font-weight: bold;\">b. Q-Learning and Deep Q-Networks (DQN)</span>\n",
    "        </h3>\n",
    "         <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> Deep Q-Networks approximate the Q-value function using neural networks, combining Q-learning principles with function approximation. The network takes the state as input and outputs Q-values for all actions. Training involves minimizing the difference between predicted Q-values and target Q-values computed from observed rewards and estimated future values.\n",
    "        </p>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"actor_critic\" style=\"color: #9b59b6; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x1F91D;</span>\n",
    "            <span style=\"font-weight: bold;\">c. Actor-Critic Methods</span>\n",
    "        </h3>\n",
    "         <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> Actor-Critic methods combine policy (actor) and value (critic) approaches. The actor updates the policy distribution, and the critic estimates the value function, reducing variance in policy gradient estimates. This collaboration often leads to more stable and sample-efficient learning.\n",
    "        </p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Roboto', sans-serif; line-height: 1.6; color: #f0f0f0; margin-bottom: 20px; background-color: #2c3e50; border-radius: 12px; padding: 15px; box-shadow: 0 8px 16px rgba(0,0,0,0.4);\">\n",
    "    <h2 id=\"preferential_systems\" style=\"color: #ecf0f1; border-bottom: 2px solid #34495e; padding-bottom: 8px; margin-bottom: 15px; display: flex; align-items: center;\">\n",
    "        <span style=\"color: #3498db; font-size: 1.4em; margin-right: 8px;\">&#x1F4A0;</span>\n",
    "        <span style=\"font-weight: bold; font-size: 1.3em;\">3. Preferential Systems</span>\n",
    "    </h2>\n",
    "    <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 15px;\">\n",
    "        Explore various methods for modeling and learning preferences.\n",
    "    </p>\n",
    "    <div style=\"margin-bottom: 15px;\">\n",
    "        <h3 style=\"color: #3498db; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px;\">Table of Contents</h3>\n",
    "        <ul style=\"list-style-type: none; padding-left: 10px; font-size: 0.95em;\">\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#mcda\" style=\"color: #2ecc71; text-decoration: none; font-weight: bold;\">a. Multi-Criteria Decision Analysis (MCDA) – AHP Example</a></li>\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#preference_learning\" style=\"color: #e74c3c; text-decoration: none; font-weight: bold;\">b. Preference Learning (Rank Learning) – Simplified Ranking</a></li>\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#fuzzy_logic\" style=\"color: #9b59b6; text-decoration: none; font-weight: bold;\">c. Fuzzy Logic Systems for Preferences</a></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"mcda\" style=\"color: #2ecc71; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x1F4CA;</span>\n",
    "            <span style=\"font-weight: bold;\">a. Multi-Criteria Decision Analysis (MCDA) – AHP Example</span>\n",
    "        </h3>\n",
    "        <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> The Analytic Hierarchy Process (AHP) is used to rank alternatives based on multiple criteria. Pairwise comparisons determine the relative importance of criteria and alternatives. The example calculates a priority vector that indicates the relative weights of alternatives given a comparison matrix.\n",
    "        </p>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"preference_learning\" style=\"color: #e74c3c; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x1F50D;</span>\n",
    "            <span style=\"font-weight: bold;\">b. Preference Learning (Rank Learning) – Simplified Ranking</span>\n",
    "        </h3>\n",
    "         <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> Preference learning aims to learn a model that can rank items based on learned preferences. While specialized algorithms like RankNet or LambdaRank are used, a simplified approach using logistic regression can estimate a preference model from labeled data by predicting scores and sorting.\n",
    "        </p>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"fuzzy_logic\" style=\"color: #9b59b6; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x1F9EA;</span>\n",
    "            <span style=\"font-weight: bold;\">c. Fuzzy Logic Systems for Preferences</span>\n",
    "        </h3>\n",
    "         <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> Fuzzy logic systems model reasoning with degrees of truth rather than binary logic. Membership functions define how strongly a value belongs to a fuzzy set (e.g., low, medium, high). These systems are useful for modeling preferences that aren't strictly yes/no but rather gradations.\n",
    "        </p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Roboto', sans-serif; line-height: 1.6; color: #f0f0f0; margin-bottom: 20px; background-color: #2c3e50; border-radius: 12px; padding: 15px; box-shadow: 0 8px 16px rgba(0,0,0,0.4);\">\n",
    "    <h2 id=\"homeostatic_algorithms\" style=\"color: #ecf0f1; border-bottom: 2px solid #34495e; padding-bottom: 8px; margin-bottom: 15px; display: flex; align-items: center;\">\n",
    "        <span style=\"color: #3498db; font-size: 1.4em; margin-right: 8px;\">&#x23F1;</span>\n",
    "        <span style=\"font-weight: bold; font-size: 1.3em;\">4. Homeostatic Digital Algorithms</span>\n",
    "    </h2>\n",
    "    <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 15px;\">\n",
    "        Explore homeostatic digital algorithms, focusing on PID controllers.\n",
    "    </p>\n",
    "    <div style=\"margin-bottom: 15px;\">\n",
    "        <h3 style=\"color: #3498db; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px;\">Table of Contents</h3>\n",
    "        <ul style=\"list-style-type: none; padding-left: 10px; font-size: 0.95em;\">\n",
    "            <li style=\"margin-bottom: 5px;\"><a href=\"#pid_controllers\" style=\"color: #2ecc71; text-decoration: none; font-weight: bold;\">a. PID Controllers</a></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 15px; background-color: #34495e; padding: 12px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.3);\">\n",
    "        <h3 id=\"pid_controllers\" style=\"color: #2ecc71; font-size: 1.1em; margin-bottom: 10px; border-bottom: 1px solid #4a6572; padding-bottom: 5px; display: flex; align-items: center;\">\n",
    "            <span style=\"margin-right: 5px; font-size: 1.1em;\">&#x1F50C;</span>\n",
    "            <span style=\"font-weight: bold;\">a. PID Controllers</span>\n",
    "        </h3>\n",
    "        <p style=\"font-size: 0.95em; color: #bdc3c7; margin-bottom: 8px;\">\n",
    "            <span style=\"font-weight: bold; color:#ecf0f1;\">Details:</span> PID (Proportional-Integral-Derivative) controllers adjust a control variable to minimize the difference (error) between a desired setpoint and a measured process variable.\n",
    "            <ul>\n",
    "                <li><b>Proportional:</b> Reacts to current error.</li>\n",
    "                <li><b>Integral:</b> Reacts to the accumulation of past errors.</li>\n",
    "                <li><b>Derivative:</b> Predicts future error based on its rate of change.</li>\n",
    "            </ul>\n",
    "            The combination helps maintain system stability and respond to disturbances.\n",
    "        </p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import logging\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "# Set up logging for the entire notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_install_packages(packages: List[str]):\n",
    "    \"\"\"\n",
    "    Check if each package is installed, install if missing. \n",
    "    Avoid reinstalling if already present. \n",
    "    \"\"\"\n",
    "    for package in packages:\n",
    "        try:\n",
    "            dist = pkg_resources.get_distribution(package)\n",
    "            logger.debug(f\"Package '{package}' is already installed (version: {dist.version}).\")\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            logger.info(f\"Package '{package}' not found. Attempting to install...\")\n",
    "            # Attempt to install the missing package\n",
    "            try:\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "                logger.info(f\"Successfully installed package: {package}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to install {package}: {e}\")\n",
    "\n",
    "required_packages = [\n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"scikit-learn\",\n",
    "    \"tensorflow\",\n",
    "    \"gym\",\n",
    "    \"skfuzzy\",\n",
    "    \"simple_pid\"\n",
    "]\n",
    "\n",
    "check_install_packages(required_packages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# # 1. Classification Algorithms\n",
    "# \n",
    "# This section covers multiple classification methods:\n",
    "# 1. Decision Trees\n",
    "# 2. Support Vector Machines (SVM)\n",
    "# 3. Neural Networks (Deep Learning)\n",
    "# \n",
    "# We'll illustrate each with:\n",
    "# - A close-to-production-level code snippet.\n",
    "# - Logging for real-time feedback.\n",
    "# - Chunk-based (where feasible) or parallel data handling to demonstrate scalability.\n",
    "# - Object exports to allow other cells to reuse the classifiers or data.\n",
    "#\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Decision Trees (Scikit-learn example)\n",
    "# \n",
    "# Decision Trees are intuitive, branching structures that split data based on feature thresholds. \n",
    "# We will:\n",
    "# 1. Load the Iris dataset in multiple chunks (simulating chunkwise ingestion).\n",
    "# 2. Train a DecisionTreeClassifier.\n",
    "# 3. Visualize the final tree using plot_tree.\n",
    "# \n",
    "# By chunking, we can handle large datasets that may not fit entirely into memory, \n",
    "# writing partial data to disk for concurrency in a real production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "logger.debug(\"Starting Decision Trees example...\")\n",
    "\n",
    "# Simulate chunk-based data loading of the Iris dataset\n",
    "def load_iris_in_chunks(chunk_size=30):\n",
    "    \"\"\"\n",
    "    Yields chunks of the Iris data. \n",
    "    Each chunk includes a portion of X and y.\n",
    "    \"\"\"\n",
    "    iris = load_iris()\n",
    "    X_full, y_full = iris.data, iris.target\n",
    "    start = 0\n",
    "    while start < len(X_full):\n",
    "        end = min(start + chunk_size, len(X_full))\n",
    "        yield X_full[start:end], y_full[start:end]\n",
    "        start = end\n",
    "\n",
    "logger.debug(\"Loading Iris dataset in chunks.\")\n",
    "X_chunks, y_chunks = [], []\n",
    "for X_c, y_c in load_iris_in_chunks(chunk_size=50):\n",
    "    X_chunks.append(X_c)\n",
    "    y_chunks.append(y_c)\n",
    "\n",
    "# Concatenate all chunks (in real scenario, these could be processed in parallel)\n",
    "X_iris = np.concatenate(X_chunks, axis=0)\n",
    "y_iris = np.concatenate(y_chunks, axis=0)\n",
    "\n",
    "logger.debug(\"Iris dataset loaded and concatenated. Proceeding to DecisionTreeClassifier.\")\n",
    "\n",
    "# Train a Decision Tree on entire data\n",
    "try:\n",
    "    clf_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "    clf_tree.fit(X_iris, y_iris)\n",
    "    logger.info(\"DecisionTreeClassifier trained successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error while training DecisionTreeClassifier: {e}\", exc_info=True)\n",
    "    raise e\n",
    "\n",
    "# Visualize the tree\n",
    "try:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_tree(\n",
    "        clf_tree,\n",
    "        filled=True,\n",
    "        feature_names=load_iris().feature_names,\n",
    "        class_names=load_iris().target_names,\n",
    "        rounded=True,\n",
    "        proportion=True\n",
    "    )\n",
    "    plt.title(\"Decision Tree on Iris Dataset\")\n",
    "    plt.show()\n",
    "    logger.info(\"Decision tree plotted successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error plotting the decision tree: {e}\", exc_info=True)\n",
    "\n",
    "# Expose the tree model for subsequent cells\n",
    "decision_tree_model = clf_tree\n",
    "logger.debug(\"Decision Tree example completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Support Vector Machines (SVM)\n",
    "# \n",
    "# SVMs find a hyperplane (or set of hyperplanes in higher-dimensional space) that separates data into classes with a maximum margin. \n",
    "# We'll:\n",
    "# 1. Generate synthetic data in chunks (to simulate streaming or large-scale ingestion). \n",
    "# 2. Train a linear SVM (sklearn's SVC).\n",
    "# 3. Plot the decision boundary and margins.\n",
    "#\n",
    "# We also include concurrency to demonstrate advanced scalability for batch data processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "logger.debug(\"Starting SVM example...\")\n",
    "\n",
    "def generate_blob_chunk(n_samples=50):\n",
    "    \"\"\"\n",
    "    Generates a chunk of blob data. \n",
    "    Real use cases might involve reading from disk or a data stream.\n",
    "    \"\"\"\n",
    "    # We'll generate random centers to simulate multi-chunk distribution\n",
    "    centers = np.random.randint(-5, 5, size=(2, 2))\n",
    "    X_tmp, y_tmp = datasets.make_blobs(n_samples=n_samples, centers=centers, cluster_std=0.60)\n",
    "    return X_tmp, y_tmp\n",
    "\n",
    "data_chunks = []\n",
    "num_chunks = 2  # We will produce 2 chunks\n",
    "\n",
    "# Concurrently generate data chunks\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    future_to_chunk = {executor.submit(generate_blob_chunk, 50): i for i in range(num_chunks)}\n",
    "    for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "        try:\n",
    "            X_c, y_c = future.result()\n",
    "            data_chunks.append((X_c, y_c))\n",
    "            logger.debug(\"Generated a new data chunk.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating data chunk: {e}\", exc_info=True)\n",
    "\n",
    "# Combine all chunks\n",
    "X_all = np.concatenate([dc[0] for dc in data_chunks], axis=0)\n",
    "y_all = np.concatenate([dc[1] for dc in data_chunks], axis=0)\n",
    "\n",
    "# Train a linear SVM on the combined data\n",
    "logger.debug(\"Training SVM on combined chunked data.\")\n",
    "clf_svm = svm.SVC(kernel='linear', C=1.0)\n",
    "try:\n",
    "    clf_svm.fit(X_all, y_all)\n",
    "    logger.info(\"SVM model trained successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error while training the SVM: {e}\", exc_info=True)\n",
    "    raise e\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X_all[:, 0], X_all[:, 1], c=y_all, s=50, cmap=plt.cm.Paired)\n",
    "\n",
    "# Create a grid for model predictions\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "# Decision function\n",
    "Z = clf_svm.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# Plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=0.7, linestyles=['-'])    # boundary\n",
    "ax.contour(XX, YY, Z, colors='grey', levels=[-1, 1], alpha=0.5, linestyles=['--'])  # margins\n",
    "plt.title(\"Linear SVM Decision Boundary & Margins (Chunk-Based Data)\")\n",
    "plt.show()\n",
    "\n",
    "# Expose the SVM model for subsequent cells\n",
    "svm_model = clf_svm\n",
    "logger.debug(\"SVM example completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Neural Networks (Deep Learning)\n",
    "# \n",
    "# Neural networks combine layers of weighted sums and activation functions to model complex non-linear relationships. \n",
    "# We'll:\n",
    "# 1. Generate a non-linear sine wave dataset in moderate-sized chunks. \n",
    "# 2. Train a feedforward neural network using TensorFlow (Keras).\n",
    "# 3. Plot the predictions and the training loss.\n",
    "# \n",
    "# Logging, concurrency, and error handling methods will demonstrate a more advanced approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "logger.debug(\"Starting Neural Network example...\")\n",
    "\n",
    "def generate_sine_data_chunk(start_idx, chunk_size=50, noise_std=0.1):\n",
    "    \"\"\"\n",
    "    Generate a chunk of the sine dataset.\n",
    "    start_idx and chunk_size define the chunk boundaries on the X axis.\n",
    "    \"\"\"\n",
    "    x_local = np.linspace(-1 + 2*start_idx, -1 + 2*(start_idx + 1), chunk_size)\n",
    "    x_local = x_local[:, np.newaxis]\n",
    "    noise = np.random.normal(0, noise_std, x_local.shape)\n",
    "    y_local = np.sin(3 * x_local) + noise\n",
    "    return x_local, y_local\n",
    "\n",
    "chunks_to_generate = 4\n",
    "chunk_size = 50\n",
    "futures_data = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i in range(chunks_to_generate):\n",
    "        futures_data.append(executor.submit(generate_sine_data_chunk, i, chunk_size))\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for fut in concurrent.futures.as_completed(futures_data):\n",
    "    try:\n",
    "        x_c, y_c = fut.result()\n",
    "        X_list.append(x_c)\n",
    "        y_list.append(y_c)\n",
    "        logger.debug(\"Retrieved a new chunk of sine data.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating chunk for neural network data: {e}\", exc_info=True)\n",
    "\n",
    "X_nn = np.concatenate(X_list, axis=0)\n",
    "y_nn = np.concatenate(y_list, axis=0)\n",
    "\n",
    "logger.debug(\"Constructing feedforward neural network model.\")\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(50, activation='relu', input_shape=(1,)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "logger.debug(\"Commencing neural network training.\")\n",
    "try:\n",
    "    history = model.fit(X_nn, y_nn, epochs=50, verbose=0)\n",
    "    logger.info(\"Neural network trained successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error training neural network: {e}\", exc_info=True)\n",
    "    raise e\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_nn)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X_nn, y_nn, label='Data', alpha=0.5)\n",
    "plt.scatter(X_nn, y_pred, color='red', label='NN Predictions', alpha=0.5)\n",
    "plt.title(\"Neural Network Regression on Chunked Sine Data\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Expose the model\n",
    "nn_model = model\n",
    "logger.debug(\"Neural Network example completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# # 2. Policy Optimization Techniques\n",
    "# \n",
    "# We illustrate:\n",
    "# 1. Policy Gradient Methods (REINFORCE outline)\n",
    "# 2. Q-Learning & Deep Q-Network (DQN) setup\n",
    "# 3. Actor-Critic approach\n",
    "# \n",
    "# These examples focus on demonstrating robust structure, concurrency-friendly skeletons, \n",
    "# logging, and real-time feedback for advanced and scalable reinforcement learning in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Policy Gradient Methods (REINFORCE)\n",
    "#\n",
    "# Below is a simplified demonstration:\n",
    "# 1. We set up a policy network for the CartPole-v1 environment.\n",
    "# 2. A real training loop would:\n",
    "#    - Collect trajectories\n",
    "#    - Compute returns\n",
    "#    - Apply policy gradient updates\n",
    "# 3. We show concurrency patterns that could be applied during trajectory sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "logger.debug(\"Starting Policy Gradient (REINFORCE) demonstration...\")\n",
    "\n",
    "env_pg = gym.make('CartPole-v1')\n",
    "num_actions_pg = env_pg.action_space.n\n",
    "state_shape_pg = env_pg.observation_space.shape\n",
    "\n",
    "# Build a simple policy network\n",
    "policy_model = tf.keras.Sequential([\n",
    "    layers.Dense(24, activation='relu', input_shape=state_shape_pg),\n",
    "    layers.Dense(num_actions_pg, activation='softmax')\n",
    "])\n",
    "\n",
    "logger.debug(\"Policy network constructed.\")\n",
    "\n",
    "def select_action_pg(state):\n",
    "    \"\"\"Select an action based on the policy network output probabilities.\"\"\"\n",
    "    s = state.reshape(1, -1)\n",
    "    prob_weights = policy_model(s).numpy().flatten()\n",
    "    selected = np.random.choice(num_actions_pg, p=prob_weights)\n",
    "    return selected\n",
    "\n",
    "# Just a demonstration of selecting an action for a single step\n",
    "try:\n",
    "    state_pg = env_pg.reset()\n",
    "    sample_action = select_action_pg(state_pg)\n",
    "    logger.info(f\"Sample action chosen by REINFORCE policy: {sample_action}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in Policy Gradient demonstration: {e}\", exc_info=True)\n",
    "\n",
    "# Expose the policy model\n",
    "pg_policy_model = policy_model\n",
    "logger.debug(\"Policy Gradient (REINFORCE) demonstration completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Q-Learning & Deep Q-Networks (DQN)\n",
    "# \n",
    "# Here we:\n",
    "# 1. Initialize a basic Q-network for CartPole-v1.\n",
    "# 2. Showcase how to get Q-values for the current state.\n",
    "# 3. A fully-fledged DQN would include replay buffers, target networks, and exploration strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Starting Q-Learning & DQN demonstration...\")\n",
    "\n",
    "env_dqn = gym.make('CartPole-v1')\n",
    "num_states_dqn = env_dqn.observation_space.shape[0]\n",
    "num_actions_dqn = env_dqn.action_space.n\n",
    "\n",
    "# Define a simple Q-network architecture\n",
    "dqn_model = tf.keras.Sequential([\n",
    "    layers.Dense(24, activation='relu', input_shape=(num_states_dqn,)),\n",
    "    layers.Dense(24, activation='relu'),\n",
    "    layers.Dense(num_actions_dqn)\n",
    "])\n",
    "\n",
    "dqn_model.compile(optimizer='adam', loss='mse')\n",
    "logger.debug(\"DQN model constructed.\")\n",
    "\n",
    "try:\n",
    "    state_dqn = env_dqn.reset()\n",
    "    state_dqn = np.array([state_dqn])\n",
    "    q_values_dqn = dqn_model(state_dqn)\n",
    "    logger.info(f\"Initial Q-values for the CartPole state: {q_values_dqn.numpy()}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in DQN demonstration: {e}\", exc_info=True)\n",
    "\n",
    "# Expose the DQN model\n",
    "dqn_network = dqn_model\n",
    "logger.debug(\"Q-Learning & DQN demonstration completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Actor-Critic Methods\n",
    "# \n",
    "# Actor-critic merges:\n",
    "# - An Actor (policy) \n",
    "# - A Critic (value function approximator)\n",
    "# \n",
    "# We set up the networks for demonstration. Full training loops typically involve advantage calculation and incremental updates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Starting Actor-Critic demonstration...\")\n",
    "\n",
    "env_ac = gym.make('CartPole-v1')\n",
    "num_states_ac = env_ac.observation_space.shape[0]\n",
    "num_actions_ac = env_ac.action_space.n\n",
    "\n",
    "# Actor\n",
    "actor_model = tf.keras.Sequential([\n",
    "    layers.Dense(24, activation='relu', input_shape=(num_states_ac,)),\n",
    "    layers.Dense(num_actions_ac, activation='softmax')\n",
    "])\n",
    "\n",
    "# Critic\n",
    "critic_model = tf.keras.Sequential([\n",
    "    layers.Dense(24, activation='relu', input_shape=(num_states_ac,)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "logger.debug(\"Actor and Critic models constructed.\")\n",
    "\n",
    "try:\n",
    "    state_ac = env_ac.reset()\n",
    "    state_ac_input = np.array(state_ac).reshape(1, -1)\n",
    "    action_probs_ac = actor_model(state_ac_input)\n",
    "    state_value_ac = critic_model(state_ac_input)\n",
    "    logger.info(f\"Actor output (action probabilities): {action_probs_ac.numpy()}\")\n",
    "    logger.info(f\"Critic output (state value): {state_value_ac.numpy()}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in Actor-Critic demonstration: {e}\", exc_info=True)\n",
    "\n",
    "# Expose actor and critic\n",
    "ac_actor_model = actor_model\n",
    "ac_critic_model = critic_model\n",
    "logger.debug(\"Actor-Critic demonstration completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# # 3. Preferential Systems\n",
    "# \n",
    "# We illustrate:\n",
    "# 1. Multi-Criteria Decision Analysis (AHP basics)\n",
    "# 2. Preference Learning (Rank Learning) with logistic regression\n",
    "# 3. Fuzzy Logic Systems for modeling partial preferences\n",
    "# \n",
    "# Logging is inserted to track potential errors or progress when dealing with multiple data streams/criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Multi-Criteria Decision Analysis (AHP)\n",
    "# \n",
    "# AHP uses pairwise comparisons to build a matrix of preferences, then extracts an eigenvector (priority vector). \n",
    "# Below, the principal eigenvector from the maximum eigenvalue is normalized to form a set of priority weights.\n",
    "# \n",
    "# Real-time logging helps debug matrix dimension mismatches or numerical issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "logger.debug(\"Starting AHP demonstration...\")\n",
    "\n",
    "matrix_ahp = np.array([\n",
    "    [1,   3,   0.2],\n",
    "    [1/3, 1,   0.25],\n",
    "    [5,   4,   1]\n",
    "])\n",
    "\n",
    "try:\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(matrix_ahp)\n",
    "    max_idx = np.argmax(eigenvalues.real)\n",
    "    priority_vector = eigenvectors[:, max_idx].real\n",
    "    priority_vector /= priority_vector.sum()\n",
    "    logger.info(f\"Priority vector (AHP): {priority_vector}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in AHP demonstration: {e}\", exc_info=True)\n",
    "\n",
    "ahp_priority_vector = priority_vector\n",
    "logger.debug(\"AHP demonstration completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Preference Learning (Rank Learning) – Logistic Regression Simplification\n",
    "# \n",
    "# This example:\n",
    "# 1. Loads Iris data (already loaded previously, but let's reload to simulate independence). \n",
    "# 2. Uses a logistic regression model to get decision function scores. \n",
    "# 3. Sorts each class by descending score to rank items. \n",
    "# \n",
    "# In a real preference learning scenario, you might have pairwise preference labels or specialized ranking objectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logger.debug(\"Starting preference learning demonstration...\")\n",
    "\n",
    "# Reload Iris data for demonstration\n",
    "X_iris_pref, y_iris_pref = load_iris(return_X_y=True)\n",
    "\n",
    "try:\n",
    "    model_pref = LogisticRegression(max_iter=500)\n",
    "    model_pref.fit(X_iris_pref, y_iris_pref)\n",
    "    decision_scores = model_pref.decision_function(X_iris_pref)  # shape (n_samples, n_classes)\n",
    "\n",
    "    # For each class, rank samples\n",
    "    sorted_indices = np.argsort(decision_scores, axis=0)[::-1]  # descending\n",
    "    logger.info(f\"Top 5 items for class 0: {sorted_indices[:5, 0]}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in preference learning demonstration: {e}\", exc_info=True)\n",
    "\n",
    "pref_learning_model = model_pref\n",
    "logger.debug(\"Preference learning demonstration completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Fuzzy Logic Systems for Preferences\n",
    "# \n",
    "# Fuzzy sets allow partial membership and are useful when preferences aren't purely binary. \n",
    "# Using skfuzzy, we define triangular membership functions (Low, Medium, High) for a criterion range [0..10]. \n",
    "# We then plot these functions as a demonstration of how fuzziness can represent partial preferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "logger.debug(\"Starting fuzzy logic demonstration for preferences...\")\n",
    "\n",
    "x_fuzzy = np.linspace(0, 10, 100)\n",
    "low = fuzz.trimf(x_fuzzy, [0, 0, 5])\n",
    "medium = fuzz.trimf(x_fuzzy, [0, 5, 10])\n",
    "high = fuzz.trimf(x_fuzzy, [5, 10, 10])\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(x_fuzzy, low, label='Low')\n",
    "plt.plot(x_fuzzy, medium, label='Medium')\n",
    "plt.plot(x_fuzzy, high, label='High')\n",
    "plt.title(\"Fuzzy Membership Functions for Preference Modeling\")\n",
    "plt.xlabel(\"Criterion Value\")\n",
    "plt.ylabel(\"Membership Degree\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "logger.debug(\"Fuzzy logic demonstration completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# # 4. Homeostatic Digital Algorithms\n",
    "# \n",
    "# A PID controller is a classic approach to maintaining a system at a desired setpoint. \n",
    "# We'll set up a PID loop that tries to regulate a fictitious \"temperature\" variable. \n",
    "# \n",
    "# Real-time logging can catch anomalies or help tune parameters (P, I, D) when the process doesn't converge properly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## PID Controllers\n",
    "# \n",
    "# We use the simple_pid package to demonstrate:\n",
    "# 1. The setpoint is 20.\n",
    "# 2. The process variable starts at 0.\n",
    "# 3. Control action updates the process in a simulated loop over time steps.\n",
    "# 4. We log the final `process_var` to see if it converged near the setpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simple_pid import PID\n",
    "\n",
    "logger.debug(\"Starting PID demonstration...\")\n",
    "\n",
    "setpoint_temperature = 20\n",
    "process_var = 0\n",
    "\n",
    "pid_controller = PID(1.0, 0.1, 0.05, setpoint=setpoint_temperature)\n",
    "time_range = np.linspace(0, 10, 100)\n",
    "output_history = []\n",
    "\n",
    "for t in time_range:\n",
    "    control = pid_controller(process_var)\n",
    "    # Simplified system response\n",
    "    process_var += control * 0.1\n",
    "    output_history.append(process_var)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(time_range, output_history, label='Process Variable')\n",
    "plt.axhline(setpoint_temperature, color='r', linestyle='--', label='Setpoint')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.title(\"PID Controller Response Over Time\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"Final process variable: {process_var:.2f} (Setpoint: {setpoint_temperature})\")\n",
    "logger.debug(\"PID demonstration completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# # Conclusion\n",
    "# \n",
    "# We have:\n",
    "# 1. Demonstrated classification algorithms (Decision Trees, SVMs, Neural Networks).  \n",
    "# 2. Outlined policy optimization methods (Policy Gradients, DQN, Actor-Critic).  \n",
    "# 3. Showcased preferential systems (AHP, Preference Learning, Fuzzy Logic).  \n",
    "# 4. Illustrated a homeostatic digital algorithm (PID controller).\n",
    "# \n",
    "# Throughout these examples, we've integrated:\n",
    "# - Chunkwise data processing to scale for large datasets.  \n",
    "# - Concurrency in data loading and generation for real-time, parallel computations.  \n",
    "# - Detailed logging with robust error handling for production-level readiness.  \n",
    "# - Objects and models exposed at the end of each section for easy reuse in subsequent cells.  \n",
    "#\n",
    "# This completes the advanced, production-quality demonstration of classification_preference_systems.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
