async_mode: asyncio
concurrent_requests: 1

chunking:
  type: tokens
  size: 800
  overlap: 100
  encoding_model: o200k_base

input:
  type: text
  encoding: utf-8
  file_pattern: ".*\\.txt$$"

input_storage:
  type: file
  base_dir: input

output_storage:
  type: file
  base_dir: output

update_output_storage:
  type: file
  base_dir: update_output

reporting:
  type: file
  base_dir: logs

cache:
  type: json
  storage:
    type: file
    base_dir: cache

completion_models:
  default_completion_model:
    type: litellm
    model_provider: openai
    model: qwen2.5:1.5b
    auth_method: api_key
    api_key: ollama
    api_base: http://127.0.0.1:11434/v1
    call_args:
      temperature: 0.0
      max_tokens: 384
      max_completion_tokens: 384
      timeout: 120

embedding_models:
  default_embedding_model:
    type: litellm
    model_provider: openai
    model: nomic-embed-text:latest
    auth_method: api_key
    api_key: ollama
    api_base: http://127.0.0.1:11434/v1
    call_args:
      encoding_format: float
      user: graphrag
      timeout: 120

embed_text:
  embedding_model_id: default_embedding_model

extract_graph:
  completion_model_id: default_completion_model
  max_gleanings: 1

summarize_descriptions:
  completion_model_id: default_completion_model
  max_length: 500

extract_claims:
  enabled: false

community_reports:
  completion_model_id: default_completion_model
  max_length: 2000
  max_input_length: 8000

global_search:
  completion_model_id: default_completion_model
  data_max_tokens: 4096
  map_max_length: 600
  reduce_max_length: 1200

local_search:
  completion_model_id: default_completion_model
  embedding_model_id: default_embedding_model
  max_context_tokens: 4096
