import pytest
from spacy.tokens import Doc
@pytest.mark.parametrize('words,heads,deps,pos,chunk_offsets', [(['un', 'pollo'], [1, 1], ['det', 'ROOT'], ['DET', 'NOUN'], [(0, 2)]), (['il', 'mio', 'cane'], [2, 2, 2], ['det', 'det:poss', 'ROOT'], ['DET', 'DET', 'NOUN'], [(0, 3)]), (['il', 'cane', 'mio'], [1, 1, 1], ['det', 'ROOT', 'det:poss'], ['DET', 'NOUN', 'DET'], [(0, 3)]), (['È', 'molto', 'bello', 'il', 'vestito', 'che', 'hai', 'acquistato'], [2, 2, 2, 4, 2, 7, 7, 4], ['cop', 'advmod', 'ROOT', 'det', 'nsubj', 'obj', 'aux', 'acl:relcl'], ['AUX', 'ADV', 'ADJ', 'DET', 'NOUN', 'PRON', 'AUX', 'VERB'], [(3, 5), (5, 6)]), (['il', 'computer', 'che', 'hai', 'comprato'], [1, 1, 4, 4, 1], ['det', 'ROOT', 'nsubj', 'aux', 'acl:relcl'], ['DET', 'NOUN', 'PRON', 'AUX', 'VERB'], [(0, 2), (2, 3)]), (['Una', 'macchina', 'grande'], [1, 1, 1], ['det', 'ROOT', 'amod'], ['DET', 'NOUN', 'ADJ'], [(0, 3)]), (['mucche', 'bianche'], [0, 0], ['ROOT', 'amod'], ['NOUN', 'ADJ'], [(0, 2)]), (['Una', 'grande', 'macchina'], [2, 2, 2], ['det', 'amod', 'ROOT'], ['DET', 'ADJ', 'NOUN'], [(0, 3)]), (["Un'", 'importante', 'associazione'], [2, 2, 2], ['det', 'amod', 'ROOT'], ['DET', 'ADJ', 'NOUN'], [(0, 3)]), (['Un', 'cane', 'piccolo', 'e', 'marrone'], [1, 1, 1, 4, 2], ['det', 'ROOT', 'amod', 'cc', 'conj'], ['DET', 'NOUN', 'ADJ', 'CCONJ', 'ADJ'], [(0, 5)]), (['le', 'Nazioni', 'Unite'], [1, 1, 1], ['det', 'ROOT', 'flat:name'], ['DET', 'PROPN', 'PROPN'], [(0, 3)]), (['alcuni', 'contadini', 'molto', 'ricchi'], [1, 1, 3, 1], ['det', 'ROOT', 'advmod', 'amod'], ['DET', 'NOUN', 'ADV', 'ADJ'], [(0, 4)]), (['Ho', 'un', 'cane', 'e', 'un', 'gatto'], [0, 2, 0, 5, 5, 0], ['ROOT', 'det', 'obj', 'cc', 'det', 'conj'], ['VERB', 'DET', 'NOUN', 'CCONJ', 'DET', 'NOUN'], [(1, 3), (4, 6)]), (['lo', 'scrittore', 'brasiliano', 'Aníbal', 'Machado'], [1, 1, 1, 1, 3], ['det', 'ROOT', 'amod', 'nmod', 'flat:name'], ['DET', 'NOUN', 'ADJ', 'PROPN', 'PROPN'], [(0, 3), (3, 5)]), (['Dom', 'Pedro', 'II'], [0, 0, 0], ['ROOT', 'flat:name', 'flat:name'], ['PROPN', 'PROPN', 'PROPN'], [(0, 3)]), (['gli', 'Stati', 'Uniti'], [1, 1, 1], ['det', 'ROOT', 'flat:name'], ['DET', 'PROPN', 'PROPN'], [(0, 3)]), (['la', 'distruzione', 'della', 'città'], [1, 1, 3, 1], ['det', 'ROOT', 'case', 'nmod'], ['DET', 'NOUN', 'ADP', 'NOUN'], [(0, 2), (3, 4)]), (['la', 'prima', 'fabbrica', 'di', 'droga', 'del', 'governo'], [2, 2, 2, 4, 2, 6, 2], ['det', 'amod', 'ROOT', 'case', 'nmod', 'case', 'nmod'], ['DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'ADP', 'NOUN'], [(0, 3), (4, 5), (6, 7)]), (['Traduzione', 'del', 'rapporto', 'di', 'Susana'], [0, 2, 0, 4, 2], ['ROOT', 'case', 'nmod', 'case', 'nmod'], ['NOUN', 'ADP', 'NOUN', 'ADP', 'PROPN'], [(0, 1), (2, 3), (4, 5)]), (['Il', 'gatto', 'grasso', 'di', 'Susana', 'e', 'la', 'sua', 'amica'], [1, 1, 1, 4, 1, 8, 8, 8, 1], ['det', 'ROOT', 'amod', 'case', 'nmod', 'cc', 'det', 'det:poss', 'conj'], ['DET', 'NOUN', 'ADJ', 'ADP', 'PROPN', 'CCONJ', 'DET', 'DET', 'NOUN'], [(0, 3), (4, 5), (6, 9)]), (['La', 'nuova', 'spesa', 'è', 'alimentata', 'dal', 'grande', 'conto', 'in', 'banca', 'di', 'Clinton'], [2, 2, 4, 4, 4, 7, 7, 4, 9, 7, 11, 9], ['det', 'amod', 'nsubj:pass', 'aux:pass', 'ROOT', 'case', 'amod', 'obl:agent', 'case', 'nmod', 'case', 'nmod'], ['DET', 'ADJ', 'NOUN', 'AUX', 'VERB', 'ADP', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'ADP', 'PROPN'], [(0, 3), (6, 8), (9, 10), (11, 12)]), (['Ma', 'mentre', 'questo', 'prestito', 'possa', 'ora', 'sembrare', 'gestibile', ',', 'un', 'improvviso', 'cambiamento', 'delle', 'circostanze', 'potrebbe', 'portare', 'a', 'problemi', 'di', 'debitii'], [15, 6, 3, 6, 6, 6, 15, 6, 6, 11, 11, 15, 13, 11, 15, 15, 17, 15, 19, 17], ['cc', 'mark', 'det', 'nsubj', 'aux', 'advmod', 'advcl', 'xcomp', 'punct', 'det', 'amod', 'nsubj', 'case', 'nmod', 'aux', 'ROOT', 'case', 'obl', 'case', 'nmod'], ['CCONJ', 'SCONJ', 'DET', 'NOUN', 'AUX', 'ADV', 'VERB', 'ADJ', 'PUNCT', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'AUX', 'VERB', 'ADP', 'NOUN', 'ADP', 'NOUN'], [(2, 4), (9, 12), (13, 14), (17, 18), (19, 20)])])
def test_it_noun_chunks(it_vocab, words, heads, deps, pos, chunk_offsets):
    doc = Doc(it_vocab, words=words, heads=heads, deps=deps, pos=pos)
    assert [(c.start, c.end) for c in doc.noun_chunks] == chunk_offsets