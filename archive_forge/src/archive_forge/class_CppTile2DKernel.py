import contextlib
import dataclasses
import functools
import itertools
import logging
import math
import re
import sys
from copy import copy, deepcopy
from typing import Dict, List, Optional, Set, Tuple, Union
import sympy
import torch
import torch.fx
from torch._inductor import dependencies
from torch._inductor.ir import StorageBox, TensorBox
from torch._prims_common import is_float_dtype
from torch.utils._sympy.functions import FloorDiv
from torch.utils._sympy.value_ranges import bound_sympy, ValueRanges
from .. import codecache, config, ir, metrics
from ..codegen.wrapper import WrapperCodeGen
from ..optimize_indexing import range_expressable_in_32_bits
from ..scheduler import BaseScheduling, SchedulerNode
from ..utils import (
from ..virtualized import ops, V
from .common import (
class CppTile2DKernel(CppVecKernel):
    """
    A vector kernel that handles the 2d tiles with the tile size defined in `tiling_factor` on
    the inner-most loop level and one of the outer loop level (`outer_tiling_idx`). When the data
    tile is accessed in a contiguous way from the outer loop axis, a transposition is applied on the
    tile to make the access contiguous from the inner-most loop axis. Then, the same vectorization
    logic from its parent `CppVecKernel` is leveraged for load/store/compute. The transposed tile load
    and store are generated into kernel.preloads and kernel.poststores buffers.

    The loop structure looks like below:
    for ...
      for i_outer ...
        for ...
          for inner_most ...
            // generated by CppTile2DKernel
            float tmp0[16*16]; at::vec::transpose_mxn<...>(tmp0, in_ptr0 + ..., ...); // into kernel.preloads
            float tmp1[16*16]; // into kernel.preloads
            for i_inner ... { // the kernel inner loop
              vectorized loads/compute/stores (e.g., load tmp0, store tmp1) // into kernel.loads/compute/stores
            }
            at::vec::transpose_mxn(out_ptr0 + ..., tmp1, ...) // into kernel.poststores
          for inner_most ... (tail)
            // generated by CppVecKernel
            ...
      for i_outer ... (tail)
        for ...
          for ...
            // generated by CppKernel
            ...
    """

    def __init__(self, args, num_threads, tiling_factor, tiling_indices, tiling_dtype):
        super().__init__(args, num_threads, tiling_factor, tiling_indices[1], tiling_dtype)
        self.tiling_indices = tiling_indices

    def inner_itervar(self):
        return sympy_symbol(f'{self.itervars[self.outer_idx]}_inner')

    def need_vec_transpose(self, index):
        return stride_at(self.itervars[self.outer_idx], index) == 1 and index.has(self.itervars[self.tiling_idx]) and (not stride_at(self.itervars[self.tiling_idx], index).has(self.itervars[self.tiling_idx])) and (not stride_at(self.itervars[self.tiling_idx], index).has(self.itervars[self.outer_idx]))

    def gen_transposed_tile_load_store(self, name, var, index, is_store):
        dtype = V.graph.get_dtype(name)
        factor = self.tiling_factor
        src = f'{var} + {cexpr_index(index)}'
        dst = '__place_holder__'
        ld_src = f'{cexpr_index(stride_at(self.itervars[self.tiling_idx], index))}'
        ld_dst = f'{factor}'
        if is_store:
            src, dst = (dst, src)
            ld_src, ld_dst = (ld_dst, ld_src)
        need_define = True
        load_or_store = f'at::vec::transpose_mxn<{DTYPE_TO_CPP[dtype]},{factor},{factor}>({src}, {ld_src}, {dst}, {ld_dst});'
        if is_store:
            tile_var = self.cse.newvar()
        elif load_or_store not in self.cse.cache:
            tile_var = self.cse.generate(self.preloads, load_or_store, write=False)
        else:
            need_define = False
            tile_var = self.cse.cache[load_or_store]
        if need_define:
            define_line = f'{DTYPE_TO_CPP[dtype]} {tile_var}[{factor}*{factor}] __attribute__ ((aligned ({factor})));'
            self.preloads.writeline(define_line)
        load_or_store = load_or_store.replace('__place_holder__', str(tile_var))
        if is_store:
            self.poststores.writeline(DeferredLine(name, load_or_store))
        else:
            self.preloads.writeline(load_or_store)
        return tile_var

    def load(self, name: str, index: sympy.Expr):
        opt_ctx: OptimizationContext = get_current_node_opt_ctx()
        var = self.args.input(name)
        index = self.rename_indexing(index)
        inner = self.inner_itervar()
        if self.need_vec_transpose(index):
            tile_var = self.gen_transposed_tile_load_store(name, var, index, is_store=False)
            loadbuf = f'{tile_var} + {cexpr_index(inner * self.tiling_factor)}'
            dtype = V.graph.get_dtype(name)
            if dtype in DTYPE_LOWP_FP:
                line = f'at::vec::Vectorized<{DTYPE_TO_CPP[dtype]}>::loadu({loadbuf}, {self.tiling_factor})'
            elif V.graph.get_dtype(name) in [torch.uint8] and opt_ctx.is_load_uint8_as_float:
                line = f'at::vec::Vectorized<uint8_t>::loadu_one_fourth({loadbuf})'
            else:
                line = f'at::vec::Vectorized<float>::loadu({loadbuf})'
            csevar = self.cse.generate(self.loads, line)
            csevar.update_on_args('load', (name, index), {})
            assert isinstance(csevar, CppCSEVariable)
            csevar.is_vec = True
            return csevar
        else:
            new_index = self.scale_index_with_offset(index, itervar_idx=self.outer_idx, offset=inner)
            return super().load(name, new_index)

    def store(self, name, index, value, mode=None):
        assert 'buf' in name
        opt_ctx: OptimizationContext = get_current_node_opt_ctx()
        var = self.args.output(name)
        inner = self.inner_itervar()
        index = self.rename_indexing(index)
        assert mode is None
        if self.need_vec_transpose(index):
            tile_var = self.gen_transposed_tile_load_store(name, var, index, is_store=True)
            storebuf = f'{tile_var} + {cexpr_index(inner * self.tiling_factor)}'
            if V.graph.get_dtype(name) in DTYPE_LOWP_FP:
                line = f'{value}.store({storebuf}, {self.tiling_factor});'
            elif V.graph.get_dtype(name) in [torch.uint8]:
                line = f'{value}.store({storebuf}, {self.tiling_factor});'
            else:
                line = f'{value}.store({storebuf});'
            self.stores.writeline(DeferredLine(name, line))
        else:
            new_index = self.scale_index_with_offset(index, itervar_idx=self.outer_idx, offset=inner)
            super().store(name, new_index, value, mode)

    def codegen_inner_loops(self, code):
        inner = self.inner_itervar()
        code.writeline(f'for (long {inner} = 0; {inner} < {self.tiling_factor}; {inner}++)')

    def set_ranges(self, group, reduction_group):
        vars = super().set_ranges(group, reduction_group)
        self.outer_idx, self.tiling_idx = self.tiling_indices if self.tiling_indices[1] < self.reduction_depth else reversed(self.tiling_indices)
        return vars