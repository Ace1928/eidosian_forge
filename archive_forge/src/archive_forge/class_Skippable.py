from typing import (
from torch import Tensor, nn
from ..microbatch import Batch
from .namespace import Namespace
from .tracker import current_skip_tracker
class Skippable(nn.Module):
    """The base class for skippable modules.

    Do not use this class directly. Define a subclass by :func:`skippable`
    instead.

    """
    module_cls: ClassVar[Type[SkippableModule]]
    stashable_names: ClassVar[FrozenSet[str]]
    poppable_names: ClassVar[FrozenSet[str]]

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__()
        self.module = self.module_cls(*args, **kwargs)
        self.namespaces: Dict[str, Namespace] = {}

    def __repr__(self) -> str:
        return f'@skippable({self.module})'

    def namespaced(self, name: str) -> Tuple[Namespace, str]:
        """Prepend namespace for the given skip name."""
        ns = self.namespaces.get(name)
        ns = cast(Namespace, ns)
        return (ns, name)

    def stashable(self) -> Iterable[Tuple[Namespace, str]]:
        """Iterate over namespaced skip names to be stashed."""
        for name in self.stashable_names:
            yield self.namespaced(name)

    def poppable(self) -> Iterable[Tuple[Namespace, str]]:
        """Iterate over namespaced skip names to be popped."""
        for name in self.poppable_names:
            yield self.namespaced(name)

    def isolate(self: T, ns: Namespace, *, only: Optional[Iterable[str]]=None) -> T:
        """Isolate a specified subset or the whole set of skip tensors.

        In a single sequential module, skip tensors with the same
        name are not allowed unless they are isolated by different namespaces.

        Here's an example using the same name for skip tensors twice. Each pair
        of ``Layer1`` and ``Layer2`` is isolated with its own namespace ``ns1``
        and ``ns2``. There is no conflict anymore::

            ns1 = Namespace()
            ns2 = Namespace()

            model = nn.Sequential(
                Layer1().isolate(ns1),
                Layer1().isolate(ns2),
                Layer2(),
                Layer3().isolate(ns2),
                Layer3().isolate(ns1),
            )

        When `only` parameter is omitted, all skip tensors are isolated. You
        can isolate a subset of skip tensors by passing `only` parameter::

            ns_alice = Namespace()
            ns_bob = Namespace()

            model = nn.Sequential(
                ...
                StashStashPop().isolate(ns_alice, only=['alice']) \\
                               .isolate(ns_bob, only=['bob']),
                ...
            )

        Args:
            ns (Namespace):
                namespace for isolation

        Keyword Args:
            only (iterable of strs):
                names of specific skip tensors to be isolated (omit this option
                to isolate all skip tensors declared in this module)

        Returns:
            this module itself

        """
        names: Iterable[str]
        if only is None:
            names = self.stashable_names | self.poppable_names
        else:
            names = set(only)
        for name in names:
            self.namespaces[name] = ns
        return self

    def dispatch(self, input, handle_stash: Callable[[str, Optional[Tensor]], None], handle_pop: Callable[[str], Optional[Tensor]]):
        """Dispatch :class:`stash` or :class:`pop` commands.

        The commands are generated by the module's ``forward()``.
        """
        generator = self.module(input)
        if not isinstance(generator, Generator):
            output = generator
            return output
        try:
            op = next(generator)
            while True:
                if isinstance(op, stash):
                    handle_stash(op.name, op.tensor)
                    op = next(generator)
                    continue
                if isinstance(op, pop):
                    tensor = handle_pop(op.name)
                    op = generator.send(tensor)
                    continue
                raise TypeError(f'{op!r} is not a command from @skippable')
        except StopIteration as stop:
            output = stop.args[0]
            return output

    def forward(self, input: Union[List[Any], Tensor]) -> TensorOrTensors:
        """Perform the forward propagation.

        :class:`stash` or :class:`pop` commands will be handled by portals
        silently. The portals won't be exposed to users.

        Raises:
            RuntimeError:
                illegal 'stash' or 'pop' is found.

        """
        skip_tracker = current_skip_tracker()
        stashed_tensors: Dict[str, Optional[Tensor]] = {}
        poppable_tensors = {}
        batch = Batch(input)
        for ns, name in self.poppable():
            try:
                poppable_tensors[name] = skip_tracker.load(batch, ns, name)
            except KeyError as e:
                raise RuntimeError(f"'{name}' has not been stashed") from e
        input = batch.values

        def handle_stash(name: str, tensor: Optional[Tensor]) -> None:
            if name not in self.stashable_names:
                raise RuntimeError(f"'{name}' has not been declared as stashable")
            stashed_tensors[name] = tensor

        def handle_pop(name: str) -> Optional[Tensor]:
            if name not in self.poppable_names:
                raise RuntimeError(f"'{name}' has not been declared as poppable")
            return poppable_tensors.pop(name)
        output = self.dispatch(input, handle_stash, handle_pop)
        not_stashed = self.stashable_names - stashed_tensors.keys()
        if not_stashed:
            comma_names = ', '.join((f"'{n}'" for n in not_stashed))
            raise RuntimeError(f'{comma_names} must be stashed but have not')
        not_popped = poppable_tensors.keys()
        if not_popped:
            comma_names = ', '.join((f"'{n}'" for n in not_popped))
            raise RuntimeError(f'{comma_names} must be popped but have not')
        batch = Batch(output)
        for ns, name in self.stashable():
            tensor = stashed_tensors[name]
            skip_tracker.save(batch, ns, name, tensor)
        output = batch.values
        return output