import collections
import pickle
import threading
import time
import timeit
from absl import flags
from absl import logging
import gym
import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow.python.distribute import values as values_lib  
from tensorflow.python.framework import composite_tensor  
from tensorflow.python.framework import tensor_conversion_registry  
def get_non_dying_envs(envs_needing_reset, reset_mask, env_ids):
    """Returns which transitions are valid or generated before an env. restarted.

  Args:
    envs_needing_reset: <int32>[num_envs_needing_reset] tensor with the IDs
      of the environments that need a reset.
    reset_mask: <bool>[inference_batch_size] tensor that contains True for
      transitions that triggered an environment reset (i.e. transition whose
      run_id does not match the previously store run_id for the corresponding
      environment).
    env_ids: <int32>[inference_batch_size] tensor of environment ID for each
      transition in the inference batch.

  Returns:
    A pair:
      - <bool>[inference_batch_size] tensor, True when the transition comes from
        a non-dying actor. False for the transitions generated by an environment
        before the transition that triggered a reset. This will typically be the
        last generated transitions before an environment restarts.
      - <int32>[num_nondying_envs] tensor, IDs of the envs that are not dying.
  """
    envs_needing_reset_mask = tf.reduce_any(tf.equal(env_ids, tf.expand_dims(envs_needing_reset, -1)), axis=0)
    dying_envs_mask = tf.logical_and(envs_needing_reset_mask, tf.logical_not(reset_mask))
    num_dying_envs = tf.reduce_sum(tf.cast(dying_envs_mask, tf.int32))
    if tf.not_equal(num_dying_envs, 0):
        tf.print('Found', num_dying_envs, 'transitions from dying environments. Dying environment IDs:', tf.boolean_mask(env_ids, dying_envs_mask), 'Dying environments mask:', dying_envs_mask)
    nondying_envs_mask = tf.logical_not(dying_envs_mask)
    nondying_env_ids = tf.boolean_mask(env_ids, nondying_envs_mask)
    unique_nondying_env_ids, _, unique_nondying_env_ids_count = tf.unique_with_counts(nondying_env_ids)
    tf.debugging.Assert(tf.equal(tf.shape(nondying_env_ids)[0], tf.shape(unique_nondying_env_ids)[0]), data=[tf.gather(unique_nondying_env_ids, tf.where(unique_nondying_env_ids_count >= 2)[:0]), nondying_env_ids], summarize=4096)
    return (nondying_envs_mask, nondying_env_ids)