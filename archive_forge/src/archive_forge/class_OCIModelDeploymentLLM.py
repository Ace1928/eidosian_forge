import logging
from typing import Any, Dict, List, Optional
import requests
from langchain_core.callbacks import CallbackManagerForLLMRun
from langchain_core.language_models.llms import LLM
from langchain_core.pydantic_v1 import Field, root_validator
from langchain_core.utils import get_from_dict_or_env
class OCIModelDeploymentLLM(LLM):
    """Base class for LLM deployed on OCI Data Science Model Deployment."""
    auth: dict = Field(default_factory=dict, exclude=True)
    'ADS auth dictionary for OCI authentication:\n    https://accelerated-data-science.readthedocs.io/en/latest/user_guide/cli/authentication.html.\n    This can be generated by calling `ads.common.auth.api_keys()`\n    or `ads.common.auth.resource_principal()`. If this is not\n    provided then the `ads.common.default_signer()` will be used.'
    max_tokens: int = 256
    'Denotes the number of tokens to predict per generation.'
    temperature: float = 0.2
    'A non-negative float that tunes the degree of randomness in generation.'
    k: int = 0
    'Number of most likely tokens to consider at each step.'
    p: float = 0.75
    'Total probability mass of tokens to consider at each step.'
    endpoint: str = ''
    'The uri of the endpoint from the deployed Model Deployment model.'
    best_of: int = 1
    'Generates best_of completions server-side and returns the "best"\n    (the one with the highest log probability per token).\n    '
    stop: Optional[List[str]] = None
    'Stop words to use when generating. Model output is cut off\n    at the first occurrence of any of these substrings.'

    @root_validator()
    def validate_environment(cls, values: Dict) -> Dict:
        """Validate that python package exists in environment."""
        try:
            import ads
        except ImportError as ex:
            raise ImportError('Could not import ads python package. Please install it with `pip install oracle_ads`.') from ex
        if not values.get('auth', None):
            values['auth'] = ads.common.auth.default_signer()
        values['endpoint'] = get_from_dict_or_env(values, 'endpoint', 'OCI_LLM_ENDPOINT')
        return values

    @property
    def _default_params(self) -> Dict[str, Any]:
        """Default parameters for the model."""
        raise NotImplementedError

    @property
    def _identifying_params(self) -> Dict[str, Any]:
        """Get the identifying parameters."""
        return {**{'endpoint': self.endpoint}, **self._default_params}

    def _construct_json_body(self, prompt: str, params: dict) -> dict:
        """Constructs the request body as a dictionary (JSON)."""
        raise NotImplementedError

    def _invocation_params(self, stop: Optional[List[str]], **kwargs: Any) -> dict:
        """Combines the invocation parameters with default parameters."""
        params = self._default_params
        if self.stop is not None and stop is not None:
            raise ValueError('`stop` found in both the input and default params.')
        elif self.stop is not None:
            params['stop'] = self.stop
        elif stop is not None:
            params['stop'] = stop
        else:
            params['stop'] = []
        return {**params, **kwargs}

    def _process_response(self, response_json: dict) -> str:
        raise NotImplementedError

    def _call(self, prompt: str, stop: Optional[List[str]]=None, run_manager: Optional[CallbackManagerForLLMRun]=None, **kwargs: Any) -> str:
        """Call out to OCI Data Science Model Deployment endpoint.

        Args:
            prompt (str):
                The prompt to pass into the model.
            stop (List[str], Optional):
                List of stop words to use when generating.
            kwargs:
                requests_kwargs:
                    Additional ``**kwargs`` to pass to requests.post

        Returns:
            The string generated by the model.

        Example:
            .. code-block:: python

                response = oci_md("Tell me a joke.")

        """
        requests_kwargs = kwargs.pop('requests_kwargs', {})
        params = self._invocation_params(stop, **kwargs)
        body = self._construct_json_body(prompt, params)
        logger.info(f'LLM API Request:\n{prompt}')
        response = self._send_request(data=body, endpoint=self.endpoint, **requests_kwargs)
        completion = self._process_response(response)
        logger.info(f'LLM API Completion:\n{completion}')
        return completion

    def _send_request(self, data: Any, endpoint: str, header: Optional[dict]={}, **kwargs: Any) -> Dict:
        """Sends request to the oci data science model deployment endpoint.

        Args:
            data (Json serializable):
                data need to be sent to the endpoint.
            endpoint (str):
                The model HTTP endpoint.
            header (dict, optional):
                A dictionary of HTTP headers to send to the specified url.
                Defaults to {}.
            kwargs:
                Additional ``**kwargs`` to pass to requests.post.
        Raises:
            Exception:
                Raise when invoking fails.

        Returns:
            A JSON representation of a requests.Response object.
        """
        if not header:
            header = {}
        header['Content-Type'] = header.pop('content_type', DEFAULT_CONTENT_TYPE_JSON) or DEFAULT_CONTENT_TYPE_JSON
        request_kwargs = {'json': data}
        request_kwargs['headers'] = header
        timeout = kwargs.pop('timeout', DEFAULT_TIME_OUT)
        attempts = 0
        while attempts < 2:
            request_kwargs['auth'] = self.auth.get('signer')
            response = requests.post(endpoint, timeout=timeout, **request_kwargs, **kwargs)
            if response.status_code == 401:
                self._refresh_signer()
                attempts += 1
                continue
            break
        try:
            response.raise_for_status()
            response_json = response.json()
        except Exception:
            logger.error('DEBUG INFO: request_kwargs=%s, status_code=%s, content=%s', request_kwargs, response.status_code, response.content)
            raise
        return response_json

    def _refresh_signer(self) -> None:
        if self.auth.get('signer', None) and hasattr(self.auth['signer'], 'refresh_security_token'):
            self.auth['signer'].refresh_security_token()