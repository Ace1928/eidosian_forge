from .agents import BASE_PYTHON_TOOLS, clean_code_for_chat
from .python_interpreter import InterpretorError, evaluate
def evaluate_chat_agent(agent, verbose=False, return_errors=False):
    """
    Evaluates a new agent on all `EVALUATION_CHATS`.

    Example:

    ```py
    agent = NewOpenAiAgent(model="text-davinci-003", api_key=your_api_key)
    bads = new_evaluate_agent(agent)
    for bad in bads:
        print(bad)
    ```
    """
    agent_tools = set(agent.toolbox.keys())
    if agent_tools != set(TEST_TOOLS):
        missing_tools = set(TEST_TOOLS) - agent_tools
        unexpected_tools = agent_tools - set(TEST_TOOLS)
        raise ValueError(f'Fix the test tools in the evaluate_agent module. Tools mising: {missing_tools}. Extra tools: {unexpected_tools}.')
    tool_selection_score = 0
    tool_used_score = 0
    code_score = 0
    total_steps = 0
    if return_errors:
        tool_selection_errors = {}
        tool_used_errors = {}
        code_errors = {}
    for chat_problem in EVALUATION_CHATS:
        if isinstance(chat_problem[0].task, str):
            resolved_problems = [chat_problem]
        else:
            resolved_problems = [[Problem(task=pb.task[i], inputs=pb.inputs, answer=pb.answer) for pb in chat_problem] for i in range(len(chat_problem[0].task))]
        for problem in resolved_problems:
            agent.prepare_for_new_chat()
            agent_state = {}
            theoretical_state = [{} for _ in range(len(problem[0].answer))] if isinstance(problem[0].answer, list) else {}
            for step, step_problem in enumerate(problem):
                if verbose:
                    print(step_problem.task)
                total_steps += 1
                prompt = agent.format_prompt(step_problem.task, chat_mode=True)
                result = agent.generate_one(prompt, stop=['Human:', '====='])
                agent.chat_history = prompt + result + '\n'
                explanation, code = clean_code_for_chat(result)
                if verbose:
                    print(f'==Explanation from the agent==\n{explanation}')
                    print(f'\n==Code generated by the agent==\n{code}')
                agent_answer = evaluate_code(code, step_problem.inputs, state=agent_state, verbose=verbose)
                answer = step_problem.answer
                if isinstance(answer, list):
                    theoretical_answer = [evaluate_code(a, step_problem.inputs, state=state) for a, state in zip(answer, theoretical_state)]
                else:
                    theoretical_answer = evaluate_code(answer, step_problem.inputs, state=theoretical_state)
                scores, errors = evaluate_one_result(explanation, code, agent_answer, theoretical_answer, answer, verbose=verbose)
                tool_selection_score += scores[0]
                tool_used_score += scores[1]
                code_score += scores[2]
                if return_errors:
                    if errors[0] is not None:
                        tool_selection_errors[step_problem.task] = errors[0]
                    if errors[1] is not None:
                        tool_used_errors[step_problem.task] = errors[1]
                    if errors[2] is not None:
                        code_errors[step_problem.task] = errors[2]
    scores = {'tool selection score': 100 * (tool_selection_score / total_steps), 'tool used score': 100 * (tool_used_score / total_steps), 'code score': 100 * (code_score / total_steps)}
    if return_errors:
        return (scores, tool_selection_errors, tool_used_errors, code_errors)
    else:
        return scores