import copy
import json
import logging
import math
import os
import random
import shutil
import warnings
from pathlib import Path
from typing import Callable, Dict, List, Optional, Tuple, Union, TYPE_CHECKING
from ray.air.constants import TRAINING_ITERATION
from ray.train import Checkpoint
from ray.train._internal.session import _TrainingResult, _FutureTrainingResult
from ray.tune.error import TuneError
from ray.tune.result import DEFAULT_METRIC
from ray.tune.search import SearchGenerator
from ray.tune.utils.util import SafeFallbackEncoder
from ray.tune.search.sample import Domain, Function
from ray.tune.schedulers import FIFOScheduler, TrialScheduler
from ray.tune.search.variant_generator import format_vars
from ray.tune.experiment import Trial
from ray.util import PublicAPI
from ray.util.debug import log_once
def _checkpoint_or_exploit(self, trial: Trial, tune_controller: 'TuneController', upper_quantile: List[Trial], lower_quantile: List[Trial]):
    """Checkpoint if in upper quantile, exploits if in lower."""
    state = self._trial_state[trial]
    if trial in upper_quantile:
        logger.debug(f'Trial {trial} is in upper quantile. Saving checkpoint.')
        if trial.status == Trial.PAUSED:
            if trial.temporary_state.saving_to and isinstance(trial.temporary_state.saving_to, _FutureTrainingResult):
                logger.debug(f'Trial {trial} is still saving.')
                state.last_checkpoint = trial.temporary_state.saving_to
            else:
                logger.debug(f'Trial {trial} is paused. Use last available checkpoint {trial.checkpoint}.')
                state.last_checkpoint = trial.checkpoint
        else:
            logger.debug(f'Instructing {trial} to save.')
            state.last_checkpoint = tune_controller._schedule_trial_save(trial, result=state.last_result)
        self._num_checkpoints += 1
    else:
        state.last_checkpoint = None
    if trial in lower_quantile:
        trial_to_clone = random.choice(upper_quantile)
        assert trial is not trial_to_clone
        clone_state = self._trial_state[trial_to_clone]
        last_checkpoint = clone_state.last_checkpoint
        logger.debug(f'Trial {trial} is in lower quantile. Exploiting trial {trial_to_clone}.')
        if isinstance(last_checkpoint, _FutureTrainingResult):
            training_result = last_checkpoint.resolve()
            if training_result:
                clone_state.last_result = training_result.metrics
                clone_state.last_checkpoint = training_result.checkpoint
                last_checkpoint = clone_state.last_checkpoint
            else:
                logger.debug(f"PBT-scheduled checkpoint save resolved to None. Trial {trial_to_clone} didn't save any checkpoint before and can't be exploited.")
                last_checkpoint = None
        if not last_checkpoint:
            logger.info(f'[pbt]: no checkpoint for trial {trial_to_clone}. Skip exploit for Trial {trial}')
            return
        self._exploit(tune_controller, trial, trial_to_clone)