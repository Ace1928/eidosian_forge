from __future__ import absolute_import
from apitools.base.protorpclite import messages as _messages
from apitools.base.py import encoding
from apitools.base.py import extra_types
class GoogleCloudAiplatformV1BatchPredictionJobOutputConfig(_messages.Message):
    """Configures the output of BatchPredictionJob. See
  Model.supported_output_storage_formats for supported output formats, and how
  predictions are expressed via any of them.

  Fields:
    bigqueryDestination: The BigQuery project or dataset location where the
      output is to be written to. If project is provided, a new dataset is
      created with name `prediction__` where is made BigQuery-dataset-name
      compatible (for example, most special characters become underscores),
      and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format.
      In the dataset two tables will be created, `predictions`, and `errors`.
      If the Model has both instance and prediction schemata defined then the
      tables have columns as follows: The `predictions` table contains
      instances for which the prediction succeeded, it has columns as per a
      concatenation of the Model's instance and prediction schemata. The
      `errors` table contains rows for which the prediction has failed, it has
      instance columns, as per the instance schema, followed by a single
      "errors" column, which as values has google.rpc.Status represented as a
      STRUCT, and containing only `code` and `message`.
    gcsDestination: The Cloud Storage location of the directory where the
      output is to be written to. In the given directory a new directory is
      created. Its name is `prediction--`, where timestamp is in YYYY-MM-
      DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files
      `predictions_0001.`, `predictions_0002.`, ..., `predictions_N.` are
      created where `` depends on chosen predictions_format, and N may equal
      0001 and depends on the total number of successfully predicted
      instances. If the Model has both instance and prediction schemata
      defined then each such file contains predictions as per the
      predictions_format. If prediction for any instance failed (partially or
      completely), then an additional `errors_0001.`, `errors_0002.`,...,
      `errors_N.` files are created (N depends on total number of failed
      predictions). These files contain the failed instances, as per their
      schema, followed by an additional `error` field which as value has
      google.rpc.Status containing only `code` and `message` fields.
    predictionsFormat: Required. The format in which Vertex AI gives the
      predictions, must be one of the Model's
      supported_output_storage_formats.
  """
    bigqueryDestination = _messages.MessageField('GoogleCloudAiplatformV1BigQueryDestination', 1)
    gcsDestination = _messages.MessageField('GoogleCloudAiplatformV1GcsDestination', 2)
    predictionsFormat = _messages.StringField(3)