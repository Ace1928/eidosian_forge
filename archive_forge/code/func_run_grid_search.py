from pyomo.common.dependencies import numpy as np, numpy_available
import pyomo.environ as pyo
from pyomo.opt import SolverFactory
import pickle
from itertools import permutations, product
import logging
from enum import Enum
from pyomo.common.timing import TicTocTimer
from pyomo.contrib.sensitivity_toolbox.sens import get_dsdp
from pyomo.contrib.doe.scenario import ScenarioGenerator, FiniteDifferenceStep
from pyomo.contrib.doe.result import FisherResults, GridSearchResult
def run_grid_search(self, design_ranges, mode='sequential_finite', tee_option=False, scale_nominal_param_value=False, scale_constant_value=1, store_name=None, read_name=None, store_optimality_as_csv=None, formula='central', step=0.001):
    """
        Enumerate through full grid search for any number of design variables;
        solve square problems sequentially to compute FIMs.
        It calculates FIM with sensitivity information from two modes:

            1. sequential_finite: Calculates a one scenario model multiple times for multiple scenarios.
               Sensitivity info estimated by finite difference
            2. direct_kaug: calculate sensitivity by k_aug with direct sensitivity

        Parameters
        ----------
        design_ranges:
            a ``dict``, keys are design variable names,
            values are a list of design variable values to go over
        mode:
            choose from CalculationMode.sequential_finite, .direct_kaug.
        tee_option:
            if solver console output is made
        scale_nominal_param_value:
            if True, the parameters are scaled by its own nominal value in param_init
        scale_constant_value:
            scale all elements in Jacobian matrix, default is 1.
        store_name:
            a string of file name. If not None, store results with this name.
            It is a pickle file containing all measurement information after solving the
            model with perturbations.
            Since there are multiple experiments, results are numbered with a scalar number,
            and the result for one grid is 'store_name(count).csv' (count is the number of count).
        read_name:
            a string of file name. If not None, read result files.
            It should be a pickle file previously generated by store_name option.
            Since there are multiple experiments, this string should be the common part of all files;
            Real name of the file is "read_name(count)", where count is the number of the experiment.
        store_optimality_as_csv:
            if True, the design criterion values of grid search results stored with this file name as a csv
        formula:
            choose from FiniteDifferenceStep.central, .forward, or .backward.
            This option is only used for CalculationMode.sequential_finite.
        step:
            Sensitivity perturbation step size, a fraction between [0,1]. default is 0.001

        Returns
        -------
        figure_draw_object: a combined result object of class Grid_search_result
        """
    self.objective_option = ObjectiveLib.zero
    self.store_optimality_as_csv = store_optimality_as_csv
    self.fim_scale_constant_value = scale_constant_value ** 2
    result_combine = {}
    design_ranges_list = list(design_ranges.values())
    design_dimension_names = list(design_ranges.keys())
    count = 0
    failed_count = 0
    total_count = 1
    for rng in design_ranges_list:
        total_count *= len(rng)
    time_set = []
    search_design_set = product(*design_ranges_list)
    for design_set_iter in search_design_set:
        design_iter = self.design_vars.variable_names_value.copy()
        for i, names in enumerate(design_dimension_names):
            if type(names) is list or type(names) is tuple:
                for n in names:
                    design_iter[n] = list(design_set_iter)[i]
            else:
                design_iter[names] = list(design_set_iter)[i]
        self.design_vars.variable_names_value = design_iter
        iter_timer = TicTocTimer()
        self.logger.info('=======Iteration Number: %s =====', count + 1)
        self.logger.debug('Design variable values of this iteration: %s', design_iter)
        iter_timer.tic(msg=None)
        if store_name is None:
            store_output_name = None
        else:
            store_output_name = store_name + str(count)
        if read_name:
            read_input_name = read_name + str(count)
        else:
            read_input_name = None
        try:
            result_iter = self.compute_FIM(mode=mode, tee_opt=tee_option, scale_nominal_param_value=scale_nominal_param_value, scale_constant_value=scale_constant_value, store_output=store_output_name, read_output=read_input_name, formula=formula, step=step)
            count += 1
            result_iter.result_analysis()
            iter_t = iter_timer.toc(msg=None)
            time_set.append(iter_t)
            self.logger.info('This is run %s out of %s.', count, total_count)
            self.logger.info('The code has run  %s seconds.', sum(time_set))
            self.logger.info('Estimated remaining time:  %s seconds', sum(time_set) / (count + 1) * (total_count - count - 1))
            result_combine[tuple(design_set_iter)] = result_iter
        except:
            self.logger.warning(':::::::::::Warning: Cannot converge this run.::::::::::::')
            count += 1
            failed_count += 1
            self.logger.warning('failed count:', failed_count)
            result_combine[tuple(design_set_iter)] = None
    self.all_fim = result_combine
    figure_draw_object = GridSearchResult(design_ranges_list, design_dimension_names, result_combine, store_optimality_name=store_optimality_as_csv)
    self.logger.info('Overall wall clock time [s]:  %s', sum(time_set))
    return figure_draw_object