from unittest import TestCase
from unittest.mock import MagicMock
import pytest
from nltk.parse import corenlp
from nltk.tree import Tree
class TestTokenizerAPI(TestCase):

    def test_tokenize(self):
        corenlp_tokenizer = corenlp.CoreNLPParser()
        api_return_value = {'sentences': [{'index': 0, 'tokens': [{'after': ' ', 'before': '', 'characterOffsetBegin': 0, 'characterOffsetEnd': 4, 'index': 1, 'originalText': 'Good', 'word': 'Good'}, {'after': ' ', 'before': ' ', 'characterOffsetBegin': 5, 'characterOffsetEnd': 12, 'index': 2, 'originalText': 'muffins', 'word': 'muffins'}, {'after': ' ', 'before': ' ', 'characterOffsetBegin': 13, 'characterOffsetEnd': 17, 'index': 3, 'originalText': 'cost', 'word': 'cost'}, {'after': '', 'before': ' ', 'characterOffsetBegin': 18, 'characterOffsetEnd': 19, 'index': 4, 'originalText': '$', 'word': '$'}, {'after': '\n', 'before': '', 'characterOffsetBegin': 19, 'characterOffsetEnd': 23, 'index': 5, 'originalText': '3.88', 'word': '3.88'}, {'after': ' ', 'before': '\n', 'characterOffsetBegin': 24, 'characterOffsetEnd': 26, 'index': 6, 'originalText': 'in', 'word': 'in'}, {'after': ' ', 'before': ' ', 'characterOffsetBegin': 27, 'characterOffsetEnd': 30, 'index': 7, 'originalText': 'New', 'word': 'New'}, {'after': '', 'before': ' ', 'characterOffsetBegin': 31, 'characterOffsetEnd': 35, 'index': 8, 'originalText': 'York', 'word': 'York'}, {'after': '  ', 'before': '', 'characterOffsetBegin': 35, 'characterOffsetEnd': 36, 'index': 9, 'originalText': '.', 'word': '.'}]}, {'index': 1, 'tokens': [{'after': ' ', 'before': '  ', 'characterOffsetBegin': 38, 'characterOffsetEnd': 44, 'index': 1, 'originalText': 'Please', 'word': 'Please'}, {'after': ' ', 'before': ' ', 'characterOffsetBegin': 45, 'characterOffsetEnd': 48, 'index': 2, 'originalText': 'buy', 'word': 'buy'}, {'after': '\n', 'before': ' ', 'characterOffsetBegin': 49, 'characterOffsetEnd': 51, 'index': 3, 'originalText': 'me', 'word': 'me'}, {'after': ' ', 'before': '\n', 'characterOffsetBegin': 52, 'characterOffsetEnd': 55, 'index': 4, 'originalText': 'two', 'word': 'two'}, {'after': ' ', 'before': ' ', 'characterOffsetBegin': 56, 'characterOffsetEnd': 58, 'index': 5, 'originalText': 'of', 'word': 'of'}, {'after': '', 'before': ' ', 'characterOffsetBegin': 59, 'characterOffsetEnd': 63, 'index': 6, 'originalText': 'them', 'word': 'them'}, {'after': '\n', 'before': '', 'characterOffsetBegin': 63, 'characterOffsetEnd': 64, 'index': 7, 'originalText': '.', 'word': '.'}]}, {'index': 2, 'tokens': [{'after': '', 'before': '\n', 'characterOffsetBegin': 65, 'characterOffsetEnd': 71, 'index': 1, 'originalText': 'Thanks', 'word': 'Thanks'}, {'after': '', 'before': '', 'characterOffsetBegin': 71, 'characterOffsetEnd': 72, 'index': 2, 'originalText': '.', 'word': '.'}]}]}
        corenlp_tokenizer.api_call = MagicMock(return_value=api_return_value)
        input_string = 'Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.\nThanks.'
        expected_output = ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']
        tokenized_output = list(corenlp_tokenizer.tokenize(input_string))
        corenlp_tokenizer.api_call.assert_called_once_with('Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.\nThanks.', properties={'annotators': 'tokenize,ssplit'})
        self.assertEqual(expected_output, tokenized_output)