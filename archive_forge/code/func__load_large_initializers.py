from __future__ import annotations
import os
import sys
from typing import Any, Iterable
import numpy as np
import onnx
import onnx.external_data_helper as ext_data
import onnx.helper
import onnx.onnx_cpp2py_export.checker as c_checker
def _load_large_initializers(self, file_path):
    """Loads large initializers.

        Arguments:
            file_path: model file, the weight are expected to be in the same folder as this file
        """
    if self.model_proto_ is None:
        raise RuntimeError('A model must be loaded before loading the weights.')
    self.large_initializers = {}
    base_dir = os.path.dirname(file_path)
    for i, tensor in enumerate(ext_data._get_all_tensors(self.model_proto_)):
        if not ext_data.uses_external_data(tensor):
            continue
        info = ext_data.ExternalDataInfo(tensor)
        external_data_file_path = c_checker._resolve_external_data_location(base_dir, info.location, tensor.name)
        key = f'#t{i}'
        _set_external_data(tensor, location=key)
        with open(external_data_file_path, 'rb') as data_file:
            if info.offset:
                data_file.seek(info.offset)
            raw_data = data_file.read(info.length) if info.length else data_file.read()
            dtype = onnx.helper.tensor_dtype_to_np_dtype(tensor.data_type)
            shape = tuple(tensor.dims)
            if sys.byteorder == 'big':
                np_tensor = np.frombuffer(raw_data, dtype=dtype).byteswap().reshape(shape)
            else:
                np_tensor = np.frombuffer(raw_data, dtype=dtype).reshape(shape)
            self.large_initializers[key] = np_tensor