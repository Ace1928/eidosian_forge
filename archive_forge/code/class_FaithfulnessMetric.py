from dataclasses import dataclass, field
from typing import Any, Dict, List
from mlflow.metrics.genai.base import EvaluationExample
from mlflow.metrics.genai.prompt_template import PromptTemplate
@dataclass
class FaithfulnessMetric:
    definition = 'Faithfulness is only evaluated with the provided output and provided context, please ignore the provided input entirely when scoring faithfulness. Faithfulness assesses how much of the provided output is factually consistent with the provided context. A higher score indicates that a higher proportion of claims present in the output can be derived from the provided context. Faithfulness does not consider how much extra information from the context is not present in the output.'
    grading_prompt = 'Faithfulness: Below are the details for different scores:\n- Score 1: None of the claims in the output can be inferred from the provided context.\n- Score 2: Some of the claims in the output can be inferred from the provided context, but the majority of the output is missing from, inconsistent with, or contradictory to the provided context.\n- Score 3: Half or more of the claims in the output can be inferred from the provided context.\n- Score 4: Most of the claims in the output can be inferred from the provided context, with very little information that is not directly supported by the provided context.\n- Score 5: All of the claims in the output are directly supported by the provided context, demonstrating high faithfulness to the provided context.'
    grading_context_columns = ['context']
    parameters = default_parameters
    default_model = default_model
    example_score_2 = EvaluationExample(input='How is MLflow related to Databricks?', output='Databricks is a company that specializes in big data and machine learning solutions. MLflow has nothing to do with Databricks. MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle.', score=2, justification='The output claims that "MLflow has nothing to do with Databricks" which is contradictory to the provided context that states "It was developed by Databricks". This is a major inconsistency. However, the output correctly identifies that "MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle" and "Databricks is a company that specializes in big data and machine learning solutions", which are both supported by the context. Therefore, some of the claims in the output can be inferred from the provided context, but the majority of the output is inconsistent with the provided context, leading to a faithfulness score of 2.', grading_context={'context': 'MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is designed to address the challenges that data scientists and machine learning engineers face when developing, training, and deploying machine learning models.'})
    example_score_5 = EvaluationExample(input='How is MLflow related to Databricks?', output='Databricks is a company that specializes in big data and machine learning solutions.', score=5, justification='The output states that "Databricks is a company that specializes in big data and machine learning solutions." This claim is directly supported by the context, which states "It was developed by Databricks, a company that specializes in big data and machine learning solutions." Therefore, the faithfulness score is 5 as all the claims in the output are directly supported by the provided context."', grading_context={'context': 'MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is designed to address the challenges that data scientists and machine learning engineers face when developing, training, and deploying machine learning models.'})
    default_examples = [example_score_2, example_score_5]