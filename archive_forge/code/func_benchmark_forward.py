import torch
import torch.utils.benchmark as benchmark
def benchmark_forward(fn, *inputs, repeats=10, desc='', verbose=True, amp=False, amp_dtype=torch.float16, **kwinputs):
    """Use Pytorch Benchmark on the forward pass of an arbitrary function."""
    if verbose:
        print(desc, '- Forward pass')

    def amp_wrapper(*inputs, **kwinputs):
        with torch.autocast(device_type='cuda', dtype=amp_dtype, enabled=amp):
            fn(*inputs, **kwinputs)
    t = benchmark.Timer(stmt='fn_amp(*inputs, **kwinputs)', globals={'fn_amp': amp_wrapper, 'inputs': inputs, 'kwinputs': kwinputs}, num_threads=torch.get_num_threads())
    m = t.timeit(repeats)
    if verbose:
        print(m)
    return (t, m)