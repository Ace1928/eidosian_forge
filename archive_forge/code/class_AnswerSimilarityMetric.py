from dataclasses import dataclass, field
from typing import Any, Dict, List
from mlflow.metrics.genai.base import EvaluationExample
from mlflow.metrics.genai.prompt_template import PromptTemplate
@dataclass
class AnswerSimilarityMetric:
    definition = 'Answer similarity is evaluated on the degree of semantic similarity of the provided output to the provided targets, which is the ground truth. Scores can be assigned based on the gradual similarity in meaning and description to the provided targets, where a higher score indicates greater alignment between the provided output and provided targets.'
    grading_prompt = 'Answer similarity: Below are the details for different scores:\n- Score 1: The output has little to no semantic similarity to the provided targets.\n- Score 2: The output displays partial semantic similarity to the provided targets on some aspects.\n- Score 3: The output has moderate semantic similarity to the provided targets.\n- Score 4: The output aligns with the provided targets in most aspects and has substantial semantic similarity.\n- Score 5: The output closely aligns with the provided targets in all significant aspects.'
    grading_context_columns = ['targets']
    parameters = default_parameters
    default_model = default_model
    example_score_2 = EvaluationExample(input='What is MLflow?', output='MLflow is an open-source platform.', score=2, justification="The provided output is partially similar to the target, as it captures the general idea that MLflow is an open-source platform. However, it lacks the comprehensive details and context provided in the target about MLflow's purpose, development, and challenges it addresses. Therefore, it demonstrates partial, but not complete, semantic similarity.", grading_context={'targets': 'MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is designed to address the challenges that data scientists and machine learning engineers face when developing, training, and deploying machine learning models.'})
    example_score_4 = EvaluationExample(input='What is MLflow?', output='MLflow is an open-source platform for managing machine learning workflows, including experiment tracking, model packaging, versioning, and deployment, simplifying the ML lifecycle.', score=4, justification='The provided output aligns closely with the target. It covers various key aspects mentioned in the target, including managing machine learning workflows, experiment tracking, model packaging, versioning, and deployment. While it may not include every single detail from the target, it demonstrates substantial semantic similarity.', grading_context={'targets': 'MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is designed to address the challenges that data scientists and machine learning engineers face when developing, training, and deploying machine learning models.'})
    default_examples = [example_score_2, example_score_4]