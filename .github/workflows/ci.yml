# üöÄ Eidosian CI Pipeline v4.0.1
# Comprehensive CI/CD with formatting, linting, testing, and deployment
# Format ‚Üí Lint ‚Üí Test ‚Üí Build ‚Üí Deploy workflow
# Fixed: Removed pip caching to avoid "Maximum call stack size exceeded" in large monorepos

name: Eidosian Universal CI

on:
  push:
    branches: [main, master, develop]
    paths-ignore:
      - "**/*.md"
      - "docs/**"
      - ".github/ISSUE_TEMPLATE/**"
  pull_request:
    branches: [main, master, develop]
  workflow_dispatch:
    inputs:
      debug:
        description: "Enable runner debugging mode"
        required: false
        default: false
        type: boolean

# ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
# ‚îÉ Environment variables for all jobs    ‚îÉ
# ‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ
env:
  PYTHONUNBUFFERED: 1
  FORCE_COLOR: 1
  POETRY_VIRTUALENVS_CREATE: false
  POETRY_VERSION: "1.8.3"

# Default permissions for all jobs
permissions:
  contents: read

# Prevent duplicate workflow runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  validate:
    name: ‚öôÔ∏è Validate
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
      has_python: ${{ steps.check.outputs.has_python }}
      has_typescript: ${{ steps.check.outputs.has_typescript }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - id: check
        name: üîç Check what to run
        run: |
          echo "should_run=true" >> $GITHUB_OUTPUT

          # Resolve a reliable diff base for both push and pull_request events.
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
          elif [ -n "${{ github.event.before }}" ] && [ "${{ github.event.before }}" != "0000000000000000000000000000000000000000" ]; then
            BASE_SHA="${{ github.event.before }}"
          else
            BASE_SHA=""
          fi

          if [ -n "$BASE_SHA" ]; then
            CHANGED_FILES="$(git diff --name-only "$BASE_SHA" "${{ github.sha }}" || true)"
          else
            # Fallback for workflow_dispatch/initial commits where diff-base is unavailable.
            CHANGED_FILES="$(git ls-files)"
          fi

          printf "%s\n" "$CHANGED_FILES" > changed_files.txt

          # Check if Python files changed
          if grep -qE '\.py$' changed_files.txt || [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "has_python=true" >> $GITHUB_OUTPUT
            echo "::notice::Python files detected"
          else
            echo "has_python=false" >> $GITHUB_OUTPUT
          fi

          # Check if TypeScript/JavaScript files changed
          if grep -qE '\.(ts|tsx|js|jsx)$' changed_files.txt || [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "has_typescript=true" >> $GITHUB_OUTPUT
            echo "::notice::TypeScript/JavaScript files detected"
          else
            echo "has_typescript=false" >> $GITHUB_OUTPUT
          fi

  format-check:
    name: üé® Format Check
    needs: validate
    if: needs.validate.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading and checking format
    steps:
      - uses: actions/checkout@v4

      - name: üêç Set up Python
        if: needs.validate.outputs.has_python == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: üì¶ Install Python formatters
        if: needs.validate.outputs.has_python == 'true'
        run: |
          python -m pip install --upgrade pip
          pip install black isort

      - name: üé® Check Python formatting
        if: needs.validate.outputs.has_python == 'true'
        id: python_format
        run: |
          PYTHON_FORMAT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_FORMAT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python formatting targets found; skipping."
            exit 0
          fi

          echo "::group::Black format check"
          black "${TARGETS[@]}" --check --diff --line-length=120 || FORMAT_FAIL=1
          echo "::endgroup::"
          
          echo "::group::isort import check"
          isort "${TARGETS[@]}" --check --diff --profile=black --line-length=120 --skip-gitignore || FORMAT_FAIL=1
          echo "::endgroup::"
          
          if [ -n "$FORMAT_FAIL" ]; then
            echo "::warning::Python formatting drift detected. Continuing (non-blocking) for monorepo stability."
            echo "::notice::Run Auto Format workflow to reconcile global formatting debt."
          fi

      - name: üì¶ Set up Node.js
        if: needs.validate.outputs.has_typescript == 'true'
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: üì• Install Prettier
        if: needs.validate.outputs.has_typescript == 'true'
        run: npm install -g prettier@3.4.2

      - name: üé® Check TypeScript formatting
        if: needs.validate.outputs.has_typescript == 'true'
        run: |
          echo "::group::Prettier format check"
          prettier "**/*.{ts,tsx,js,jsx}" --check --ignore-path .gitignore --ignore-unknown --log-level warn
          echo "::endgroup::"

  lint:
    name: üßπ Lint
    needs: [validate, format-check]
    if: needs.validate.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: üì¶ Install dependencies
        id: deps
        run: |
          python -m pip install --upgrade pip setuptools wheel
          # Install linting and formatting tools directly
          pip install black isort flake8 mypy pylint ruff

      - name: üîç Check code formatting
        run: |
          PYTHON_LINT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_LINT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python lint targets found; skipping."
            exit 0
          fi

          if command -v black >/dev/null 2>&1; then
            echo "::group::Black format check"
            black "${TARGETS[@]}" --check --diff --line-length=120 || echo "::warning::Code formatting issues detected"
            echo "::endgroup::"
          else
            echo "::warning::black not installed, skipping format check"
          fi

          if command -v isort >/dev/null 2>&1; then
            echo "::group::isort import check"
            isort "${TARGETS[@]}" --check --diff --profile=black --line-length=120 --skip-gitignore || echo "::warning::Import sorting issues detected"
            echo "::endgroup::"
          else
            echo "::warning::isort not installed, skipping import check"
          fi

      - name: üî¨ Lint with flake8
        run: |
          PYTHON_LINT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_LINT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python lint targets found; skipping."
            exit 0
          fi
          if command -v flake8 >/dev/null 2>&1; then
            flake8 "${TARGETS[@]}" --count --statistics --show-source --exit-zero
          else
            echo "::warning::flake8 not installed, skipping lint check"
          fi

      - name: üß¨ Deep analysis with pylint
        run: |
          PYTHON_LINT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_LINT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python lint targets found; skipping."
            exit 0
          fi
          if command -v pylint >/dev/null 2>&1; then
            pylint --recursive=y "${TARGETS[@]}" --exit-zero || true
          else
            echo "::warning::pylint not installed, skipping deep analysis"
          fi

      - name: üìê Type check with mypy
        run: |
          PYTHON_LINT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_LINT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python lint targets found; skipping."
            exit 0
          fi
          if command -v mypy >/dev/null 2>&1; then
            mypy "${TARGETS[@]}" --show-error-codes || echo "::warning::Type checking issues detected"
          else
            echo "::warning::mypy not installed, skipping type check"
          fi

  test:
    name: üß™ Test
    needs: [validate, lint]
    if: needs.validate.outputs.should_run == 'true' && needs.lint.result == 'success'
    runs-on: ${{ matrix.os }}
    permissions:
      contents: read  # Only reading repository contents
    defaults:
      run:
        shell: bash
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.12"]
        os: [ubuntu-latest]

    steps:
      - uses: actions/checkout@v4

      - name: üêç Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          # Install testing tools directly
          pip install \
            pytest \
            pytest-cov \
            pytest-xdist \
            hypothesis \
            pytest-asyncio \
            pytest-benchmark \
            numpy \
            pydantic \
            httpx \
            requests \
            mcp \
            pandas \
            pyarrow \
            psutil \
            pyyaml \
            huggingface_hub \
            networkx \
            websockets \
            pillow \
            pygame

      - name: üîç Run tests
        run: |
          ROOT="$PWD"
          PY_PATH="$ROOT/lib"
          while IFS= read -r src_dir; do
            PY_PATH="${PY_PATH}:${ROOT}/${src_dir}"
          done < <(find . -maxdepth 2 -type d -name src | sed 's#^\./##' | sort)
          export PYTHONPATH="$PY_PATH"

          mapfile -t TEST_TARGETS < <(find . -maxdepth 2 -type d -name tests | sed 's#^\./##' | sort | grep -v '^eidos_mcp_backup_')
          if [ "${#TEST_TARGETS[@]}" -eq 0 ]; then
            echo "::notice::No tests directories discovered."
            exit 0
          fi

          FAILURES=()
          for target in "${TEST_TARGETS[@]}"; do
            proj="${target%/tests}"
            echo "::group::pytest ${target}"
            if (cd "$proj" && python -m pytest -q tests --maxfail=1 --disable-warnings); then
              echo "::notice::${proj} tests passed"
            else
              FAILURES+=("${proj}")
              echo "::error::${proj} tests failed"
            fi
            echo "::endgroup::"
          done

          if [ "${#FAILURES[@]}" -gt 0 ]; then
            echo "::error::Failing test groups: ${FAILURES[*]}"
            exit 1
          fi

      - name: üìä Coverage placeholder
        run: |
          # Per-forge test execution does not produce one root coverage.xml yet.
          # Keep this job deterministic; coverage aggregation is handled by forge-level tooling.
          cat > coverage.xml <<'XML'
          <?xml version="1.0" ?>
          <coverage version="0.0" timestamp="0" lines-valid="0" lines-covered="0" line-rate="0.0" branches-covered="0" branches-valid="0" branch-rate="0.0" complexity="0">
            <sources><source>.</source></sources>
            <packages/>
          </coverage>
          XML

      - name: üìä Upload coverage
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

  test-typescript:
    name: üß™ Test TypeScript
    needs: [validate, lint]
    if: needs.validate.outputs.should_run == 'true' && needs.validate.outputs.has_typescript == 'true' && needs.lint.result == 'success'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4

      - name: üì¶ Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: üß™ Test autoseed project
        run: |
          if [ -d "game_forge/src/autoseed" ]; then
            echo "::group::Testing autoseed"
            cd game_forge/src/autoseed
            npm install
            npm run typecheck
            npm run test:coverage
            echo "::endgroup::"
            
            # Upload coverage if exists
            if [ -f "coverage/coverage-summary.json" ]; then
              echo "### üìä TypeScript Coverage" >> $GITHUB_STEP_SUMMARY
              cat coverage/coverage-summary.json | python3 -c "import json,sys; data=json.load(sys.stdin); total=data.get('total',{}); print(f\"Lines: {total.get('lines',{}).get('pct',0):.2f}%\")" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "::notice::autoseed directory not found, skipping TypeScript tests"
          fi

      - name: üìÅ Upload TypeScript coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: typescript-coverage
          path: game_forge/src/autoseed/coverage/
          retention-days: 7

  docs:
    name: üìö Documentation
    needs: [validate, lint]
    if: needs.validate.outputs.should_run == 'true' && needs.lint.result == 'success'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          # Install documentation tools directly
          pip install sphinx sphinx-rtd-theme myst-parser

      - name: üìù Build docs
        run: |
          if [ -d "docs" ]; then
              cd docs
              if [ -f "Makefile" ]; then
                  make html
              elif [ -f "conf.py" ]; then
                  sphinx-build -b html . _build/html || {
                      echo "::warning::Sphinx build failed; emitting placeholder docs"
                      mkdir -p _build/html
                      printf '<html><body><h1>Docs build unavailable</h1></body></html>\n' > _build/html/index.html
                  }
              else
                  echo "::notice::No Sphinx config found in docs directory; emitting placeholder docs"
                  mkdir -p _build/html
                  printf '<html><body><h1>Docs not configured</h1></body></html>\n' > _build/html/index.html
              fi
          else
              echo "::warning::No docs directory found, skipping documentation build"
              mkdir -p _build/html
              echo "No documentation found" > _build/html/index.html
          fi

      - name: üì§ Upload docs
        uses: actions/upload-artifact@v4
        with:
          name: docs-${{ github.sha }}
          path: |
            docs/_build/html
            _build/html
          if-no-files-found: warn
          retention-days: 7

  build:
    name: üì¶ Build
    needs: [validate, test]
    if: needs.validate.outputs.should_run == 'true' && needs.test.result == 'success'
    runs-on: ubuntu-latest
    outputs:
      has_wheel: ${{ steps.package_meta.outputs.has_wheel }}
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install build twine setuptools wheel

      - name: üèóÔ∏è Build package
        run: |
          if [ -f pyproject.toml ]; then
              echo "::group::Building package with python -m build"
              python -m build
              echo "::endgroup::"
          elif [ -f setup.py ]; then
              echo "::group::Building package with setup.py"
              python setup.py sdist bdist_wheel
              echo "::endgroup::"
          else
              echo "::notice::No pyproject.toml or setup.py found in root - this is a monorepo"
              echo "::notice::Skipping package build as this repository contains multiple independent packages"
              mkdir -p dist
              echo "Monorepo - no root package to build" > dist/README.txt
          fi

      - name: ‚úÖ Check package
        run: |
          if [ -d "dist" ] && [ "$(ls -A dist)" ]; then
            # Check if we have actual packages (not just the README)
            if ls dist/*.{whl,tar.gz} 2>/dev/null | grep -q .; then
              echo "::group::Checking package with twine"
              twine check dist/*.{whl,tar.gz} 2>/dev/null || echo "::warning::Package validation issues detected"
              echo "::endgroup::"
            else
              echo "::notice::No packages to validate (monorepo with no root package)"
            fi
          else
            echo "::warning::No dist directory found"
          fi

      - name: üîé Detect built wheel
        id: package_meta
        run: |
          if find dist -maxdepth 1 -type f -name '*.whl' | grep -q .; then
            echo "has_wheel=true" >> $GITHUB_OUTPUT
            echo "::notice::Wheel artifact detected"
          else
            echo "has_wheel=false" >> $GITHUB_OUTPUT
            echo "::notice::No wheel artifact detected; integration install test will be skipped"
          fi

      - name: üì§ Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ github.sha }}
          path: dist/
          retention-days: 7

  integration:
    name: üß© Integration
    needs: [validate, build]
    if: github.event_name == 'push' && needs.validate.outputs.should_run == 'true' && needs.build.outputs.has_wheel == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: üì¶ Download package
        uses: actions/download-artifact@v4
        with:
          name: package-${{ github.sha }}
          path: dist/

      - name: üß™ Install and verify package
        run: |
          # Find wheel file
          WHEEL=$(find dist -name "*.whl" | head -n 1)
          if [ -z "$WHEEL" ]; then
              echo "::error::No wheel found in artifacts!"
              exit 1
          fi

          # Install wheel in isolated environment
          python -m venv test_env
          source test_env/bin/activate
          pip install --upgrade pip setuptools wheel
          pip install $WHEEL

          # Extract package name
          PKG_NAME=$(basename $WHEEL | cut -d'-' -f1 | tr '-' '_')
          echo "Testing package: $PKG_NAME"

          # Verify import works
          python -c "import $PKG_NAME; print(f'Successfully imported {$PKG_NAME}')"
        shell: bash

  pipeline:
    name: üöÄ Pipeline
    needs: [lint, test, test-typescript, docs, build, integration]
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading status from other jobs
    if: always()
    steps:
      - name: üìä Pipeline Status
        run: |
          FAILED_JOBS=()
          LINT_RESULT="${{ needs.lint.result }}"
          TEST_RESULT="${{ needs.test.result }}"
          TS_RESULT="${{ needs.test-typescript.result }}"
          DOCS_RESULT="${{ needs.docs.result }}"
          BUILD_RESULT="${{ needs.build.result }}"
          INTEGRATION_RESULT="${{ needs.integration.result }}"

          # Check each job result
          for item in \
            "lint:${LINT_RESULT}" \
            "test:${TEST_RESULT}" \
            "test-typescript:${TS_RESULT}" \
            "docs:${DOCS_RESULT}" \
            "build:${BUILD_RESULT}" \
            "integration:${INTEGRATION_RESULT}"
          do
            JOB_NAME="${item%%:*}"
            JOB_RESULT="${item##*:}"
            if [ "$JOB_RESULT" = "failure" ] || [ "$JOB_RESULT" = "cancelled" ]; then
              FAILED_JOBS+=("$JOB_NAME")
            fi
          done

          # Report results
          echo "## üöÄ Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Lint | ${{ needs.lint.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Test (Python) | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Test (TypeScript) | ${{ needs.test-typescript.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Docs | ${{ needs.docs.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build | ${{ needs.build.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration | ${{ needs.integration.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ ${#FAILED_JOBS[@]} -gt 0 ]; then
              echo "::error::Pipeline failed in jobs: ${FAILED_JOBS[*]}"
              echo "### ‚ùå Failed Jobs: ${FAILED_JOBS[*]}" >> $GITHUB_STEP_SUMMARY
              exit 1
          else
              echo "::notice::All checks passed successfully ‚úÖ"
              echo "### ‚úÖ All checks passed!" >> $GITHUB_STEP_SUMMARY
              exit 0
          fi
