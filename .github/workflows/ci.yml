# ðŸš€ Eidosian CI Pipeline v4.0.1
# Comprehensive CI/CD with formatting, linting, testing, and deployment
# Format â†’ Lint â†’ Test â†’ Build â†’ Deploy workflow
# Fixed: Removed pip caching to avoid "Maximum call stack size exceeded" in large monorepos

name: Eidosian Universal CI

on:
  push:
    branches: [main, master, develop]
    paths-ignore:
      - "**/*.md"
      - "docs/**"
      - ".github/ISSUE_TEMPLATE/**"
  pull_request:
    branches: [main, master, develop]
  workflow_dispatch:
    inputs:
      debug:
        description: "Enable runner debugging mode"
        required: false
        default: false
        type: boolean

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
# â”ƒ Environment variables for all jobs    â”ƒ
# â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
env:
  PYTHONUNBUFFERED: 1
  FORCE_COLOR: 1
  POETRY_VIRTUALENVS_CREATE: false
  POETRY_VERSION: "1.8.3"

# Default permissions for all jobs
permissions:
  contents: read

# Prevent duplicate workflow runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  validate:
    name: âš™ï¸ Validate
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
      has_python: ${{ steps.check.outputs.has_python }}
      has_typescript: ${{ steps.check.outputs.has_typescript }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - id: check
        name: ðŸ” Check what to run
        run: |
          echo "should_run=true" >> $GITHUB_OUTPUT

          # Resolve a reliable diff base for both push and pull_request events.
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
          elif [ -n "${{ github.event.before }}" ] && [ "${{ github.event.before }}" != "0000000000000000000000000000000000000000" ]; then
            BASE_SHA="${{ github.event.before }}"
          else
            BASE_SHA=""
          fi

          if [ -n "$BASE_SHA" ]; then
            CHANGED_FILES="$(git diff --name-only "$BASE_SHA" "${{ github.sha }}" || true)"
          else
            # Fallback for workflow_dispatch/initial commits where diff-base is unavailable.
            CHANGED_FILES="$(git ls-files)"
          fi

          printf "%s\n" "$CHANGED_FILES" > changed_files.txt

          # Check if Python files changed
          if grep -qE '\.py$' changed_files.txt || [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "has_python=true" >> $GITHUB_OUTPUT
            echo "::notice::Python files detected"
          else
            echo "has_python=false" >> $GITHUB_OUTPUT
          fi

          # Check if TypeScript/JavaScript files changed
          if grep -qE '\.(ts|tsx|js|jsx)$' changed_files.txt || [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "has_typescript=true" >> $GITHUB_OUTPUT
            echo "::notice::TypeScript/JavaScript files detected"
          else
            echo "has_typescript=false" >> $GITHUB_OUTPUT
          fi

  format-check:
    name: ðŸŽ¨ Format Check
    needs: validate
    if: needs.validate.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading and checking format
    steps:
      - uses: actions/checkout@v4

      - name: ðŸ Set up Python
        if: needs.validate.outputs.has_python == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: ðŸ“¦ Install Python formatters
        if: needs.validate.outputs.has_python == 'true'
        run: |
          python -m pip install --upgrade pip
          pip install black isort

      - name: ðŸŽ¨ Check Python formatting
        if: needs.validate.outputs.has_python == 'true'
        id: python_format
        run: |
          PYTHON_FORMAT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_FORMAT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python formatting targets found; skipping."
            exit 0
          fi

          echo "::group::Black format check"
          black "${TARGETS[@]}" --check --diff --line-length=120 || FORMAT_FAIL=1
          echo "::endgroup::"
          
          echo "::group::isort import check"
          isort "${TARGETS[@]}" --check --diff --profile=black --line-length=120 --skip-gitignore || FORMAT_FAIL=1
          echo "::endgroup::"
          
          if [ -n "$FORMAT_FAIL" ]; then
            echo "::error::Python formatting issues found. Run the 'Auto Format Code' workflow or run locally: black . --line-length=120 && isort . --profile=black"
            exit 1
          fi

      - name: ðŸ“¦ Set up Node.js
        if: needs.validate.outputs.has_typescript == 'true'
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: ðŸ“¥ Install Prettier
        if: needs.validate.outputs.has_typescript == 'true'
        run: npm install -g prettier@3.4.2

      - name: ðŸŽ¨ Check TypeScript formatting
        if: needs.validate.outputs.has_typescript == 'true'
        run: |
          echo "::group::Prettier format check"
          prettier "**/*.{ts,tsx,js,jsx}" --check --ignore-path .gitignore --ignore-unknown --log-level warn
          echo "::endgroup::"

  lint:
    name: ðŸ§¹ Lint
    needs: [validate, format-check]
    if: needs.validate.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: ðŸ“¦ Install dependencies
        id: deps
        run: |
          python -m pip install --upgrade pip setuptools wheel
          # Install linting and formatting tools directly
          pip install black isort flake8 mypy pylint ruff

      - name: ðŸ” Check code formatting
        run: |
          PYTHON_LINT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_LINT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python lint targets found; skipping."
            exit 0
          fi

          if command -v black >/dev/null 2>&1; then
            echo "::group::Black format check"
            black "${TARGETS[@]}" --check --diff --line-length=120 || echo "::warning::Code formatting issues detected"
            echo "::endgroup::"
          else
            echo "::warning::black not installed, skipping format check"
          fi

          if command -v isort >/dev/null 2>&1; then
            echo "::group::isort import check"
            isort "${TARGETS[@]}" --check --diff --profile=black --line-length=120 --skip-gitignore || echo "::warning::Import sorting issues detected"
            echo "::endgroup::"
          else
            echo "::warning::isort not installed, skipping import check"
          fi

      - name: ðŸ”¬ Lint with flake8
        run: |
          PYTHON_LINT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_LINT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python lint targets found; skipping."
            exit 0
          fi
          if command -v flake8 >/dev/null 2>&1; then
            flake8 "${TARGETS[@]}" --count --statistics --show-source --exit-zero
          else
            echo "::warning::flake8 not installed, skipping lint check"
          fi

      - name: ðŸ§¬ Deep analysis with pylint
        run: |
          PYTHON_LINT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_LINT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python lint targets found; skipping."
            exit 0
          fi
          if command -v pylint >/dev/null 2>&1; then
            pylint --recursive=y "${TARGETS[@]}" --exit-zero || true
          else
            echo "::warning::pylint not installed, skipping deep analysis"
          fi

      - name: ðŸ“ Type check with mypy
        run: |
          PYTHON_LINT_TARGETS=(
            "agent_forge"
            "code_forge"
            "memory_forge"
            "knowledge_forge"
            "eidos_mcp"
            "word_forge"
            "doc_forge"
            "scripts"
            "lib"
            "tests"
          )
          TARGETS=()
          for t in "${PYTHON_LINT_TARGETS[@]}"; do
            [ -e "$t" ] && TARGETS+=("$t")
          done
          if [ ${#TARGETS[@]} -eq 0 ]; then
            echo "::notice::No Python lint targets found; skipping."
            exit 0
          fi
          if command -v mypy >/dev/null 2>&1; then
            mypy "${TARGETS[@]}" --show-error-codes || echo "::warning::Type checking issues detected"
          else
            echo "::warning::mypy not installed, skipping type check"
          fi

  test:
    name: ðŸ§ª Test
    needs: [validate, lint]
    if: needs.validate.outputs.should_run == 'true' && needs.lint.result == 'success'
    runs-on: ${{ matrix.os }}
    permissions:
      contents: read  # Only reading repository contents
    defaults:
      run:
        shell: bash
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        os: [ubuntu-latest]
        include:
          - python-version: "3.12"
            os: windows-latest

    steps:
      - uses: actions/checkout@v4

      - name: ðŸ Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: ðŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          # Install testing tools directly
          pip install pytest pytest-cov pytest-xdist hypothesis

      - name: ðŸ” Run tests
        run: |
          echo "::group::Running pytest"
          if command -v pytest >/dev/null 2>&1; then
            set +e
            pytest --cov=. --cov-report=xml --cov-report=term-missing -v
            EXIT_CODE=$?
            set -e
            if [ $EXIT_CODE -eq 5 ]; then
              echo "::notice::No tests were collected - this is expected for a monorepo without root tests"
              exit 0
            fi
            if [ $EXIT_CODE -ne 0 ]; then
              echo "::error::Pytest failed with exit code $EXIT_CODE"
              exit $EXIT_CODE
            fi
          else
            echo "::error::pytest not found"
            exit 1
          fi
          echo "::endgroup::"

      - name: ðŸ“Š Upload coverage
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

  test-typescript:
    name: ðŸ§ª Test TypeScript
    needs: [validate, lint]
    if: needs.validate.outputs.should_run == 'true' && needs.validate.outputs.has_typescript == 'true' && needs.lint.result == 'success'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4

      - name: ðŸ“¦ Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: ðŸ§ª Test autoseed project
        run: |
          if [ -d "game_forge/src/autoseed" ]; then
            echo "::group::Testing autoseed"
            cd game_forge/src/autoseed
            npm install
            npm run typecheck
            npm run test:coverage
            echo "::endgroup::"
            
            # Upload coverage if exists
            if [ -f "coverage/coverage-summary.json" ]; then
              echo "### ðŸ“Š TypeScript Coverage" >> $GITHUB_STEP_SUMMARY
              cat coverage/coverage-summary.json | python3 -c "import json,sys; data=json.load(sys.stdin); total=data.get('total',{}); print(f\"Lines: {total.get('lines',{}).get('pct',0):.2f}%\")" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "::notice::autoseed directory not found, skipping TypeScript tests"
          fi

      - name: ðŸ“ Upload TypeScript coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: typescript-coverage
          path: game_forge/src/autoseed/coverage/
          retention-days: 7

  docs:
    name: ðŸ“š Documentation
    needs: [validate, lint]
    if: needs.validate.outputs.should_run == 'true' && needs.lint.result == 'success'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: ðŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          # Install documentation tools directly
          pip install sphinx sphinx-rtd-theme myst-parser

      - name: ðŸ“ Build docs
        run: |
          if [ -d "docs" ]; then
              cd docs
              if [ -f "Makefile" ]; then
                  make html
              else
                  echo "::warning::No Makefile found in docs directory"
                  mkdir -p _build/html
                  if command -v sphinx-build >/dev/null 2>&1; then
                      sphinx-build -b html . _build/html
                  else
                      echo "No sphinx found" > _build/html/index.html
                  fi
              fi
          else
              echo "::warning::No docs directory found, skipping documentation build"
              mkdir -p _build/html
              echo "No documentation found" > _build/html/index.html
          fi

      - name: ðŸ“¤ Upload docs
        uses: actions/upload-artifact@v4
        with:
          name: docs-${{ github.sha }}
          path: |
            docs/_build/html
            _build/html
          if-no-files-found: warn
          retention-days: 7

  build:
    name: ðŸ“¦ Build
    needs: [validate, test]
    if: needs.validate.outputs.should_run == 'true' && needs.test.result == 'success'
    runs-on: ubuntu-latest
    outputs:
      has_wheel: ${{ steps.package_meta.outputs.has_wheel }}
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: ðŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install build twine setuptools wheel

      - name: ðŸ—ï¸ Build package
        run: |
          if [ -f pyproject.toml ]; then
              echo "::group::Building package with python -m build"
              python -m build
              echo "::endgroup::"
          elif [ -f setup.py ]; then
              echo "::group::Building package with setup.py"
              python setup.py sdist bdist_wheel
              echo "::endgroup::"
          else
              echo "::notice::No pyproject.toml or setup.py found in root - this is a monorepo"
              echo "::notice::Skipping package build as this repository contains multiple independent packages"
              mkdir -p dist
              echo "Monorepo - no root package to build" > dist/README.txt
          fi

      - name: âœ… Check package
        run: |
          if [ -d "dist" ] && [ "$(ls -A dist)" ]; then
            # Check if we have actual packages (not just the README)
            if ls dist/*.{whl,tar.gz} 2>/dev/null | grep -q .; then
              echo "::group::Checking package with twine"
              twine check dist/*.{whl,tar.gz} 2>/dev/null || echo "::warning::Package validation issues detected"
              echo "::endgroup::"
            else
              echo "::notice::No packages to validate (monorepo with no root package)"
            fi
          else
            echo "::warning::No dist directory found"
          fi

      - name: ðŸ”Ž Detect built wheel
        id: package_meta
        run: |
          if find dist -maxdepth 1 -type f -name '*.whl' | grep -q .; then
            echo "has_wheel=true" >> $GITHUB_OUTPUT
            echo "::notice::Wheel artifact detected"
          else
            echo "has_wheel=false" >> $GITHUB_OUTPUT
            echo "::notice::No wheel artifact detected; integration install test will be skipped"
          fi

      - name: ðŸ“¤ Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ github.sha }}
          path: dist/
          retention-days: 7

  integration:
    name: ðŸ§© Integration
    needs: [validate, build]
    if: github.event_name == 'push' && needs.validate.outputs.should_run == 'true' && needs.build.outputs.has_wheel == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading repository contents
    steps:
      - uses: actions/checkout@v4

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: ðŸ“¦ Download package
        uses: actions/download-artifact@v4
        with:
          name: package-${{ github.sha }}
          path: dist/

      - name: ðŸ§ª Install and verify package
        run: |
          # Find wheel file
          WHEEL=$(find dist -name "*.whl" | head -n 1)
          if [ -z "$WHEEL" ]; then
              echo "::error::No wheel found in artifacts!"
              exit 1
          fi

          # Install wheel in isolated environment
          python -m venv test_env
          source test_env/bin/activate
          pip install --upgrade pip setuptools wheel
          pip install $WHEEL

          # Extract package name
          PKG_NAME=$(basename $WHEEL | cut -d'-' -f1 | tr '-' '_')
          echo "Testing package: $PKG_NAME"

          # Verify import works
          python -c "import $PKG_NAME; print(f'Successfully imported {$PKG_NAME}')"
        shell: bash

  pipeline:
    name: ðŸš€ Pipeline
    needs: [lint, test, test-typescript, docs, build, integration]
    runs-on: ubuntu-latest
    permissions:
      contents: read  # Only reading status from other jobs
    if: always()
    steps:
      - name: ðŸ“Š Pipeline Status
        run: |
          FAILED_JOBS=()
          LINT_RESULT="${{ needs.lint.result }}"
          TEST_RESULT="${{ needs.test.result }}"
          TS_RESULT="${{ needs.test-typescript.result }}"
          DOCS_RESULT="${{ needs.docs.result }}"
          BUILD_RESULT="${{ needs.build.result }}"
          INTEGRATION_RESULT="${{ needs.integration.result }}"

          # Check each job result
          for item in \
            "lint:${LINT_RESULT}" \
            "test:${TEST_RESULT}" \
            "test-typescript:${TS_RESULT}" \
            "docs:${DOCS_RESULT}" \
            "build:${BUILD_RESULT}" \
            "integration:${INTEGRATION_RESULT}"
          do
            JOB_NAME="${item%%:*}"
            JOB_RESULT="${item##*:}"
            if [ "$JOB_RESULT" = "failure" ] || [ "$JOB_RESULT" = "cancelled" ]; then
              FAILED_JOBS+=("$JOB_NAME")
            fi
          done

          # Report results
          echo "## ðŸš€ Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Lint | ${{ needs.lint.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Test (Python) | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Test (TypeScript) | ${{ needs.test-typescript.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Docs | ${{ needs.docs.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build | ${{ needs.build.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration | ${{ needs.integration.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ ${#FAILED_JOBS[@]} -gt 0 ]; then
              echo "::error::Pipeline failed in jobs: ${FAILED_JOBS[*]}"
              echo "### âŒ Failed Jobs: ${FAILED_JOBS[*]}" >> $GITHUB_STEP_SUMMARY
              exit 1
          else
              echo "::notice::All checks passed successfully âœ…"
              echo "### âœ… All checks passed!" >> $GITHUB_STEP_SUMMARY
              exit 0
          fi
