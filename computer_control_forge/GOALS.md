# Goals: computer_control_forge

**Version**: 0.1.0 â†’ 1.0.0
**Focus**: Physical embodiment for autonomous AI agents

---

## ðŸŽ¯ Immediate Goals (This Sprint)

- [ ] Consolidate mouse implementations (7 variants â†’ 2: standard + human-like)
- [ ] Add comprehensive unit tests for ControlService
- [ ] Add integration tests for perception system
- [ ] Implement MCP tool exposure via eidos_mcp
- [ ] Fix Wayland screenshot latency (portal â†’ grim/slurp)

## ðŸƒ Short-term Goals (1-2 Months)

- [ ] **Perception Pipeline**
  - [ ] Real-time change detection with delta encoding
  - [ ] Element tracking with persistent IDs
  - [ ] Window content classification (terminal, browser, etc.)
  
- [ ] **Action System**
  - [ ] Complex gesture support (drag, scroll, multi-key)
  - [ ] Action macros/sequences
  - [ ] Undo capability for reversible actions
  
- [ ] **Safety Enhancements**
  - [ ] Keyboard shortcut kill switch (Ctrl+Alt+Shift+K)
  - [ ] Visual feedback overlay for debugging
  - [ ] Action rate analysis and anomaly detection

- [ ] **Testing**
  - [ ] 80%+ test coverage
  - [ ] Automated visual regression tests
  - [ ] Performance benchmarks

## ðŸ”­ Long-term Vision

### The Ultimate Computer Control System

> A perception-action loop that allows an AI agent to interact with any desktop application with human-like fluency, complete situational awareness, and absolute safety guarantees.

#### Vision Features

1. **Multimodal Perception**
   - Real-time screen understanding (not just OCR)
   - UI element recognition (buttons, text fields, menus)
   - Application state inference
   - Predictive change detection

2. **Intelligent Action Planning**
   - Goal-directed action sequences
   - Error recovery and retry logic
   - Parallel action execution where safe
   - Context-aware timing

3. **Safety-First Architecture**
   - Hardware kill switch support
   - Anomaly detection (unusual click patterns)
   - Sandboxed action execution
   - Comprehensive audit trail with replay

4. **Cross-Platform Support**
   - X11 (current)
   - Wayland (partial)
   - macOS (planned)
   - Windows (planned via WSL2)

## ðŸš€ Aspirational Capabilities

### Self-Verification Loop
The system should be able to:
1. Capture screen state
2. Plan action to achieve goal
3. Execute action
4. Verify action succeeded via perception
5. Retry or adapt if failed

### Application-Specific Adapters
- **Browser Adapter**: DOM understanding, navigation, form filling
- **Terminal Adapter**: Command recognition, output parsing
- **IDE Adapter**: Code navigation, debugging integration
- **Document Adapter**: PDF, Word, spreadsheet manipulation

### Embodied Learning
- Learn from human demonstrations
- Adapt timing to match human patterns
- Recognize and avoid UI patterns that indicate errors
- Build mental models of applications

---

## ðŸ“ˆ Success Metrics

| Metric | Current | Target |
|--------|---------|--------|
| Action reliability | ~95% | 99.9% |
| Perception latency | ~500ms | <100ms |
| Test coverage | 15% | 90% |
| Mouse implementations | 7 | 2 |
| Supported platforms | 2 | 4 |

---

*"Precise control, absolute safety, full transparency."*
